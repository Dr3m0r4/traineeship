INFO:niftynet:2019-06-17 17:37:49,707: set CUDA_VISIBLE_DEVICES to 0
INFO:niftynet:2019-06-17 17:37:49,708: Import [DecayLearningRateApplication] from /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/contrib/learning_rate_schedule/decay_lr_application.py.
INFO:niftynet:2019-06-17 17:37:49,708: starting segmentation application
INFO:niftynet:2019-06-17 17:37:49,708: starting decay learning segmentation application
INFO:niftynet:2019-06-17 17:37:49,708: `csv_file = ` not found, writing to "/home/julien/traineeship/mmiv/model/image.csv" instead.
INFO:niftynet:2019-06-17 17:37:49,708: [image] search file folders, writing csv file /home/julien/traineeship/mmiv/model/image.csv
INFO:niftynet:2019-06-17 17:37:49,740: `csv_file = ` not found, writing to "/home/julien/traineeship/mmiv/model/label.csv" instead.
INFO:niftynet:2019-06-17 17:37:49,740: [label] search file folders, writing csv file /home/julien/traineeship/mmiv/model/label.csv
INFO:niftynet:2019-06-17 17:37:49,777: 

Number of subjects 581, input section names: ['subject_id', 'image', 'label']
Dataset partitioning:
-- training 406 cases (69.88%),
-- validation 0 cases (0.00%),
-- inference 175 cases (30.12%).

INFO:niftynet:2019-06-17 17:37:51,846: Image reader: loading 406 subjects from sections ('image',) as input [image]
INFO:niftynet:2019-06-17 17:37:51,847: Image reader: loading 406 subjects from sections ('label',) as input [label]
INFO:niftynet:2019-06-17 17:37:51,848: label mapping ready for label:('label',), 5 classes
INFO:niftynet:2019-06-17 17:37:52,042: initialised uniform sampler {'image': (1, 144, 144, 144, 1, 1), 'image_location': (1, 7), 'label': (1, 144, 144, 144, 1, 1), 'label_location': (1, 7)} 
WARNING:niftynet:2019-06-17 17:37:52,044: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/engine/application_initializer.py:106: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.
Instructions for updating:
`normal` is a deprecated alias for `truncated_normal`
INFO:niftynet:2019-06-17 17:37:52,045: using DenseVNet
INFO:niftynet:2019-06-17 17:37:52,048: Initialising Dataset from 406 subjects...
WARNING:niftynet:2019-06-17 17:37:52,052: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/engine/image_window_dataset.py:300: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, use
    tf.py_function, which takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    
WARNING:niftynet:2019-06-17 17:37:52,238: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/grid_warper.py:291: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-17 17:37:53,354: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:niftynet:2019-06-17 17:37:53,594: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/activation.py:68: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:niftynet:2019-06-17 17:37:55,846: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/loss_segmentation.py:157: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-17 17:37:55,853: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/loss_segmentation.py:174: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-17 17:37:55,863: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: calling sparse_reduce_sum (from tensorflow.python.ops.sparse_ops) with reduction_axes is deprecated and will be removed in a future version.
Instructions for updating:
reduction_axes is deprecated, use axis instead
INFO:niftynet:2019-06-17 17:38:06,834: Parameters from random initialisations ...
INFO:niftynet:2019-06-17 17:39:37,691: training iter 1, dice_loss=0.7906341552734375, lr=0.009999999776482582 (90.515774s)
INFO:niftynet:2019-06-17 17:39:46,886: training iter 2, dice_loss=0.7080027461051941, lr=0.009999999776482582 (9.194588s)
INFO:niftynet:2019-06-17 17:39:56,545: training iter 3, dice_loss=0.7549365162849426, lr=0.004999999888241291 (9.658376s)
INFO:niftynet:2019-06-17 17:40:07,196: training iter 4, dice_loss=0.7266138195991516, lr=0.004999999888241291 (10.650416s)
INFO:niftynet:2019-06-17 17:40:16,679: training iter 5, dice_loss=0.722299337387085, lr=0.004999999888241291 (9.482515s)
INFO:niftynet:2019-06-17 17:40:26,472: training iter 6, dice_loss=0.7205183506011963, lr=0.0024999999441206455 (9.788913s)
INFO:niftynet:2019-06-17 17:40:36,358: training iter 7, dice_loss=0.7232809066772461, lr=0.0024999999441206455 (9.885242s)
INFO:niftynet:2019-06-17 17:40:45,738: training iter 8, dice_loss=0.7130605578422546, lr=0.0024999999441206455 (9.379714s)
INFO:niftynet:2019-06-17 17:40:55,698: training iter 9, dice_loss=0.6923689246177673, lr=0.0012499999720603228 (9.959297s)
INFO:niftynet:2019-06-17 17:41:25,109: training iter 10, dice_loss=0.7032071948051453, lr=0.0012499999720603228 (29.400182s)
INFO:niftynet:2019-06-17 17:41:34,903: training iter 11, dice_loss=0.6973510384559631, lr=0.0012499999720603228 (9.778271s)
INFO:niftynet:2019-06-17 17:41:44,810: training iter 12, dice_loss=0.6977550387382507, lr=0.0006249999860301614 (9.906640s)
INFO:niftynet:2019-06-17 17:41:54,695: training iter 13, dice_loss=0.7082354426383972, lr=0.0006249999860301614 (9.884557s)
INFO:niftynet:2019-06-17 17:42:04,688: training iter 14, dice_loss=0.6949188113212585, lr=0.0006249999860301614 (9.992545s)
INFO:niftynet:2019-06-17 17:42:13,885: training iter 15, dice_loss=0.6942968368530273, lr=0.0003124999930150807 (9.196287s)
INFO:niftynet:2019-06-17 17:42:23,903: training iter 16, dice_loss=0.7231022715568542, lr=0.0003124999930150807 (10.018612s)
INFO:niftynet:2019-06-17 17:42:33,798: training iter 17, dice_loss=0.724049985408783, lr=0.0003124999930150807 (9.893802s)
INFO:niftynet:2019-06-17 17:42:43,866: training iter 18, dice_loss=0.687171459197998, lr=0.00015624999650754035 (10.068102s)
INFO:niftynet:2019-06-17 17:42:53,148: training iter 19, dice_loss=0.701985776424408, lr=0.00015624999650754035 (9.280266s)
INFO:niftynet:2019-06-17 17:43:03,066: training iter 20, dice_loss=0.7124743461608887, lr=0.00015624999650754035 (9.909013s)
INFO:niftynet:2019-06-17 17:43:13,019: training iter 21, dice_loss=0.7070789933204651, lr=7.812499825377017e-05 (9.937403s)
INFO:niftynet:2019-06-17 17:43:22,551: training iter 22, dice_loss=0.6999240517616272, lr=7.812499825377017e-05 (9.531755s)
INFO:niftynet:2019-06-17 17:43:32,106: training iter 23, dice_loss=0.7063798904418945, lr=7.812499825377017e-05 (9.551962s)
INFO:niftynet:2019-06-17 17:43:41,798: training iter 24, dice_loss=0.7123470306396484, lr=3.9062499126885086e-05 (9.691552s)
INFO:niftynet:2019-06-17 17:43:55,262: iter 25 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 17:43:55,262: training iter 25, dice_loss=0.6986517906188965, lr=3.9062499126885086e-05 (9.951473s)
INFO:niftynet:2019-06-17 17:44:04,838: training iter 26, dice_loss=0.6967388987541199, lr=3.9062499126885086e-05 (9.574441s)
INFO:niftynet:2019-06-17 17:44:14,588: training iter 27, dice_loss=0.6958156228065491, lr=1.9531249563442543e-05 (9.749711s)
INFO:niftynet:2019-06-17 17:44:23,956: training iter 28, dice_loss=0.6928096413612366, lr=1.9531249563442543e-05 (9.367519s)
INFO:niftynet:2019-06-17 17:44:33,760: training iter 29, dice_loss=0.7108721733093262, lr=1.9531249563442543e-05 (9.803518s)
INFO:niftynet:2019-06-17 17:44:43,284: training iter 30, dice_loss=0.7052352428436279, lr=9.765624781721272e-06 (9.501442s)
INFO:niftynet:2019-06-17 17:44:52,477: training iter 31, dice_loss=0.6929842829704285, lr=9.765624781721272e-06 (9.178396s)
INFO:niftynet:2019-06-17 17:45:02,219: training iter 32, dice_loss=0.7201964259147644, lr=9.765624781721272e-06 (9.740698s)
INFO:niftynet:2019-06-17 17:45:12,403: training iter 33, dice_loss=0.6982235908508301, lr=4.882812390860636e-06 (10.183837s)
INFO:niftynet:2019-06-17 17:45:21,730: training iter 34, dice_loss=0.7032458186149597, lr=4.882812390860636e-06 (9.316717s)
INFO:niftynet:2019-06-17 17:45:31,548: training iter 35, dice_loss=0.692352831363678, lr=4.882812390860636e-06 (9.817636s)
INFO:niftynet:2019-06-17 17:45:41,111: training iter 36, dice_loss=0.7016966938972473, lr=2.441406195430318e-06 (9.562257s)
INFO:niftynet:2019-06-17 17:45:50,782: training iter 37, dice_loss=0.7102711200714111, lr=2.441406195430318e-06 (9.670644s)
INFO:niftynet:2019-06-17 17:46:00,385: training iter 38, dice_loss=0.6997912526130676, lr=2.441406195430318e-06 (9.602498s)
INFO:niftynet:2019-06-17 17:46:10,367: training iter 39, dice_loss=0.6886773705482483, lr=1.220703097715159e-06 (9.981621s)
INFO:niftynet:2019-06-17 17:46:20,016: training iter 40, dice_loss=0.7022814750671387, lr=1.220703097715159e-06 (9.639429s)
INFO:niftynet:2019-06-17 17:46:29,801: training iter 41, dice_loss=0.6943693161010742, lr=1.220703097715159e-06 (9.767352s)
INFO:niftynet:2019-06-17 17:46:39,557: training iter 42, dice_loss=0.7135272026062012, lr=6.103515488575795e-07 (9.755316s)
INFO:niftynet:2019-06-17 17:46:49,215: training iter 43, dice_loss=0.7083690762519836, lr=6.103515488575795e-07 (9.657470s)
INFO:niftynet:2019-06-17 17:46:58,814: training iter 44, dice_loss=0.702934980392456, lr=6.103515488575795e-07 (9.598644s)
INFO:niftynet:2019-06-17 17:47:08,533: training iter 45, dice_loss=0.7133123278617859, lr=3.0517577442878974e-07 (9.713346s)
INFO:niftynet:2019-06-17 17:47:18,260: training iter 46, dice_loss=0.6896731853485107, lr=3.0517577442878974e-07 (9.726455s)
INFO:niftynet:2019-06-17 17:47:28,317: training iter 47, dice_loss=0.6934742331504822, lr=3.0517577442878974e-07 (10.056259s)
INFO:niftynet:2019-06-17 17:47:37,737: training iter 48, dice_loss=0.6948164105415344, lr=1.5258788721439487e-07 (9.419450s)
INFO:niftynet:2019-06-17 17:47:47,301: training iter 49, dice_loss=0.6954164505004883, lr=1.5258788721439487e-07 (9.563666s)
INFO:niftynet:2019-06-17 17:47:59,388: iter 50 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 17:47:59,407: training iter 50, dice_loss=0.7091760635375977, lr=1.5258788721439487e-07 (9.760651s)
INFO:niftynet:2019-06-17 17:48:08,684: training iter 51, dice_loss=0.6921409964561462, lr=7.629394360719743e-08 (9.260909s)
INFO:niftynet:2019-06-17 17:48:18,118: training iter 52, dice_loss=0.7037728428840637, lr=7.629394360719743e-08 (9.432947s)
INFO:niftynet:2019-06-17 17:48:27,494: training iter 53, dice_loss=0.7031086087226868, lr=7.629394360719743e-08 (9.375731s)
INFO:niftynet:2019-06-17 17:48:37,169: training iter 54, dice_loss=0.7087106704711914, lr=3.814697180359872e-08 (9.675106s)
INFO:niftynet:2019-06-17 17:48:46,681: training iter 55, dice_loss=0.7110846638679504, lr=3.814697180359872e-08 (9.505816s)
INFO:niftynet:2019-06-17 17:48:56,041: training iter 56, dice_loss=0.7021403312683105, lr=3.814697180359872e-08 (9.359777s)
INFO:niftynet:2019-06-17 17:49:05,905: training iter 57, dice_loss=0.710196316242218, lr=1.907348590179936e-08 (9.863239s)
INFO:niftynet:2019-06-17 17:49:15,644: training iter 58, dice_loss=0.7063224911689758, lr=1.907348590179936e-08 (9.739115s)
INFO:niftynet:2019-06-17 17:49:26,083: training iter 59, dice_loss=0.7219036221504211, lr=1.907348590179936e-08 (10.413202s)
INFO:niftynet:2019-06-17 17:49:35,714: training iter 60, dice_loss=0.6804847121238708, lr=9.53674295089968e-09 (9.597979s)
INFO:niftynet:2019-06-17 17:49:43,133: training iter 61, dice_loss=0.7003291249275208, lr=9.53674295089968e-09 (7.402908s)
INFO:niftynet:2019-06-17 17:50:01,491: training iter 62, dice_loss=0.7027204632759094, lr=9.53674295089968e-09 (18.357579s)
INFO:niftynet:2019-06-17 17:50:10,904: training iter 63, dice_loss=0.7343942523002625, lr=4.76837147544984e-09 (9.412102s)
INFO:niftynet:2019-06-17 17:50:19,986: training iter 64, dice_loss=0.6849403977394104, lr=4.76837147544984e-09 (9.079595s)
INFO:niftynet:2019-06-17 17:50:30,446: training iter 65, dice_loss=0.7216889262199402, lr=4.76837147544984e-09 (10.460317s)
INFO:niftynet:2019-06-17 17:50:41,884: training iter 66, dice_loss=0.7197985053062439, lr=2.38418573772492e-09 (11.437380s)
INFO:niftynet:2019-06-17 17:50:51,304: training iter 67, dice_loss=0.6821900010108948, lr=2.38418573772492e-09 (9.417356s)
INFO:niftynet:2019-06-17 17:51:00,678: training iter 68, dice_loss=0.6971573233604431, lr=2.38418573772492e-09 (9.374053s)
INFO:niftynet:2019-06-17 17:51:10,945: training iter 69, dice_loss=0.6830080151557922, lr=1.19209286886246e-09 (10.266733s)
INFO:niftynet:2019-06-17 17:51:20,809: training iter 70, dice_loss=0.6860503554344177, lr=1.19209286886246e-09 (9.825638s)
INFO:niftynet:2019-06-17 17:51:29,815: training iter 71, dice_loss=0.692303478717804, lr=1.19209286886246e-09 (9.005256s)
INFO:niftynet:2019-06-17 17:51:39,568: training iter 72, dice_loss=0.7035408020019531, lr=5.9604643443123e-10 (9.752463s)
INFO:niftynet:2019-06-17 17:51:51,117: training iter 73, dice_loss=0.6844649314880371, lr=5.9604643443123e-10 (11.548549s)
INFO:niftynet:2019-06-17 17:52:01,428: training iter 74, dice_loss=0.7195074558258057, lr=5.9604643443123e-10 (10.310622s)
INFO:niftynet:2019-06-17 17:52:12,580: iter 75 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 17:52:12,580: training iter 75, dice_loss=0.6935870051383972, lr=2.98023217215615e-10 (9.348224s)
INFO:niftynet:2019-06-17 17:52:22,840: training iter 76, dice_loss=0.7201061248779297, lr=2.98023217215615e-10 (10.259404s)
INFO:niftynet:2019-06-17 17:52:33,431: training iter 77, dice_loss=0.6998822093009949, lr=2.98023217215615e-10 (10.591013s)
INFO:niftynet:2019-06-17 17:52:42,460: training iter 78, dice_loss=0.7128683924674988, lr=1.490116086078075e-10 (9.028661s)
INFO:niftynet:2019-06-17 17:52:52,288: training iter 79, dice_loss=0.7015182375907898, lr=1.490116086078075e-10 (9.827231s)
INFO:niftynet:2019-06-17 17:53:01,636: training iter 80, dice_loss=0.6920111179351807, lr=1.490116086078075e-10 (9.339149s)
INFO:niftynet:2019-06-17 17:53:14,810: training iter 81, dice_loss=0.6970939040184021, lr=7.450580430390374e-11 (13.135705s)
INFO:niftynet:2019-06-17 17:53:24,629: training iter 82, dice_loss=0.6876762509346008, lr=7.450580430390374e-11 (9.818380s)
INFO:niftynet:2019-06-17 17:53:34,210: training iter 83, dice_loss=0.6968369483947754, lr=7.450580430390374e-11 (9.581004s)
INFO:niftynet:2019-06-17 17:53:43,992: training iter 84, dice_loss=0.6904155611991882, lr=3.725290215195187e-11 (9.781590s)
INFO:niftynet:2019-06-17 17:53:55,065: training iter 85, dice_loss=0.6907175183296204, lr=3.725290215195187e-11 (11.073031s)
INFO:niftynet:2019-06-17 17:54:04,200: training iter 86, dice_loss=0.686896800994873, lr=3.725290215195187e-11 (9.133851s)
INFO:niftynet:2019-06-17 17:54:13,891: training iter 87, dice_loss=0.7052786946296692, lr=1.8626451075975936e-11 (9.691024s)
INFO:niftynet:2019-06-17 17:54:24,546: training iter 88, dice_loss=0.7041766047477722, lr=1.8626451075975936e-11 (10.654022s)
INFO:niftynet:2019-06-17 17:54:35,158: training iter 89, dice_loss=0.6981093287467957, lr=1.8626451075975936e-11 (10.612278s)
INFO:niftynet:2019-06-17 17:54:44,459: training iter 90, dice_loss=0.7095670700073242, lr=9.313225537987968e-12 (9.276416s)
INFO:niftynet:2019-06-17 17:54:54,542: training iter 91, dice_loss=0.6976944804191589, lr=9.313225537987968e-12 (10.055201s)
INFO:niftynet:2019-06-17 17:55:05,108: training iter 92, dice_loss=0.6853427290916443, lr=9.313225537987968e-12 (10.565248s)
INFO:niftynet:2019-06-17 17:55:17,854: training iter 93, dice_loss=0.7171565890312195, lr=4.656612768993984e-12 (12.745756s)
INFO:niftynet:2019-06-17 17:55:27,309: training iter 94, dice_loss=0.7108963131904602, lr=4.656612768993984e-12 (9.454287s)
INFO:niftynet:2019-06-17 17:55:37,161: training iter 95, dice_loss=0.6958315968513489, lr=4.656612768993984e-12 (9.850209s)
INFO:niftynet:2019-06-17 17:55:47,030: training iter 96, dice_loss=0.7117136120796204, lr=2.328306384496992e-12 (9.868258s)
INFO:niftynet:2019-06-17 17:55:56,434: training iter 97, dice_loss=0.6936678290367126, lr=2.328306384496992e-12 (9.403749s)
INFO:niftynet:2019-06-17 17:56:06,032: training iter 98, dice_loss=0.7041403651237488, lr=2.328306384496992e-12 (9.590075s)
INFO:niftynet:2019-06-17 17:56:16,971: training iter 99, dice_loss=0.7136847972869873, lr=1.164153192248496e-12 (10.939580s)
INFO:niftynet:2019-06-17 17:56:31,189: iter 100 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 17:56:31,204: training iter 100, dice_loss=0.7130694389343262, lr=1.164153192248496e-12 (11.958487s)
INFO:niftynet:2019-06-17 17:56:40,943: training iter 101, dice_loss=0.6921029090881348, lr=1.164153192248496e-12 (9.724719s)
INFO:niftynet:2019-06-17 17:56:50,656: training iter 102, dice_loss=0.6887546181678772, lr=5.82076596124248e-13 (9.712518s)
INFO:niftynet:2019-06-17 17:57:00,578: training iter 103, dice_loss=0.7037795186042786, lr=5.82076596124248e-13 (9.921134s)
INFO:niftynet:2019-06-17 17:57:10,384: training iter 104, dice_loss=0.6980368494987488, lr=5.82076596124248e-13 (9.806116s)
INFO:niftynet:2019-06-17 17:57:20,107: training iter 105, dice_loss=0.6932766437530518, lr=2.91038298062124e-13 (9.722243s)
INFO:niftynet:2019-06-17 17:57:29,696: training iter 106, dice_loss=0.6900423169136047, lr=2.91038298062124e-13 (9.588713s)
INFO:niftynet:2019-06-17 17:57:39,937: training iter 107, dice_loss=0.6890144348144531, lr=2.91038298062124e-13 (10.240643s)
INFO:niftynet:2019-06-17 17:57:50,475: training iter 108, dice_loss=0.695380687713623, lr=1.45519149031062e-13 (10.537843s)
INFO:niftynet:2019-06-17 17:57:59,792: training iter 109, dice_loss=0.6916554570198059, lr=1.45519149031062e-13 (9.316437s)
INFO:niftynet:2019-06-17 17:58:09,687: training iter 110, dice_loss=0.6901667714118958, lr=1.45519149031062e-13 (9.876542s)
INFO:niftynet:2019-06-17 17:58:20,817: training iter 111, dice_loss=0.6771628260612488, lr=7.2759574515531e-14 (11.128549s)
INFO:niftynet:2019-06-17 17:58:30,497: training iter 112, dice_loss=0.6950383186340332, lr=7.2759574515531e-14 (9.680409s)
INFO:niftynet:2019-06-17 17:58:40,148: training iter 113, dice_loss=0.7183201909065247, lr=7.2759574515531e-14 (9.650068s)
INFO:niftynet:2019-06-17 17:58:51,533: training iter 114, dice_loss=0.7039069533348083, lr=3.63797872577655e-14 (11.384717s)
INFO:niftynet:2019-06-17 17:59:01,048: training iter 115, dice_loss=0.7084742188453674, lr=3.63797872577655e-14 (9.514899s)
INFO:niftynet:2019-06-17 17:59:11,186: training iter 116, dice_loss=0.6955825686454773, lr=3.63797872577655e-14 (10.137398s)
INFO:niftynet:2019-06-17 17:59:20,948: training iter 117, dice_loss=0.6941844820976257, lr=1.818989362888275e-14 (9.761458s)
INFO:niftynet:2019-06-17 17:59:32,092: training iter 118, dice_loss=0.6723446846008301, lr=1.818989362888275e-14 (11.143868s)
INFO:niftynet:2019-06-17 17:59:41,918: training iter 119, dice_loss=0.6947280764579773, lr=1.818989362888275e-14 (9.825196s)
INFO:niftynet:2019-06-17 17:59:51,973: training iter 120, dice_loss=0.7162058353424072, lr=9.094946814441375e-15 (10.033953s)
INFO:niftynet:2019-06-17 18:00:01,622: training iter 121, dice_loss=0.705489456653595, lr=9.094946814441375e-15 (9.631669s)
INFO:niftynet:2019-06-17 18:00:11,298: training iter 122, dice_loss=0.7015464901924133, lr=9.094946814441375e-15 (9.675930s)
INFO:niftynet:2019-06-17 18:00:22,584: training iter 123, dice_loss=0.6900933384895325, lr=4.5474734072206875e-15 (11.285816s)
INFO:niftynet:2019-06-17 18:00:32,654: training iter 124, dice_loss=0.7132318019866943, lr=4.5474734072206875e-15 (10.069173s)
INFO:niftynet:2019-06-17 18:00:44,233: iter 125 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 18:00:44,234: training iter 125, dice_loss=0.6915596127510071, lr=4.5474734072206875e-15 (9.269560s)
INFO:niftynet:2019-06-17 18:00:53,998: training iter 126, dice_loss=0.6972528100013733, lr=2.2737367036103438e-15 (9.762568s)
INFO:niftynet:2019-06-17 18:01:04,296: training iter 127, dice_loss=0.6941567063331604, lr=2.2737367036103438e-15 (10.297249s)
INFO:niftynet:2019-06-17 18:01:13,216: training iter 128, dice_loss=0.7051276564598083, lr=2.2737367036103438e-15 (8.920003s)
INFO:niftynet:2019-06-17 18:01:22,474: training iter 129, dice_loss=0.7132141590118408, lr=1.1368683518051719e-15 (9.256883s)
INFO:niftynet:2019-06-17 18:01:36,907: training iter 130, dice_loss=0.6979303956031799, lr=1.1368683518051719e-15 (14.423955s)
INFO:niftynet:2019-06-17 18:01:46,145: training iter 131, dice_loss=0.6867251396179199, lr=1.1368683518051719e-15 (9.202009s)
INFO:niftynet:2019-06-17 18:01:55,752: training iter 132, dice_loss=0.7043913006782532, lr=5.684341759025859e-16 (9.606709s)
INFO:niftynet:2019-06-17 18:02:06,569: training iter 133, dice_loss=0.7061331272125244, lr=5.684341759025859e-16 (10.815878s)
INFO:niftynet:2019-06-17 18:02:17,361: training iter 134, dice_loss=0.6814069747924805, lr=5.684341759025859e-16 (10.792539s)
INFO:niftynet:2019-06-17 18:02:26,525: training iter 135, dice_loss=0.6940711140632629, lr=2.8421708795129297e-16 (9.163435s)
INFO:niftynet:2019-06-17 18:02:36,402: training iter 136, dice_loss=0.7006015777587891, lr=2.8421708795129297e-16 (9.876695s)
INFO:niftynet:2019-06-17 18:02:47,598: training iter 137, dice_loss=0.7034713625907898, lr=2.8421708795129297e-16 (11.194908s)
INFO:niftynet:2019-06-17 18:02:58,266: training iter 138, dice_loss=0.6969749927520752, lr=1.4210854397564648e-16 (10.668344s)
INFO:niftynet:2019-06-17 18:03:07,826: training iter 139, dice_loss=0.7017874121665955, lr=1.4210854397564648e-16 (9.558912s)
INFO:niftynet:2019-06-17 18:03:17,681: training iter 140, dice_loss=0.6971650123596191, lr=1.4210854397564648e-16 (9.846588s)
INFO:niftynet:2019-06-17 18:03:27,602: training iter 141, dice_loss=0.7000420689582825, lr=7.105427198782324e-17 (9.905700s)
INFO:niftynet:2019-06-17 18:03:37,197: training iter 142, dice_loss=0.7018820643424988, lr=7.105427198782324e-17 (9.594774s)
INFO:niftynet:2019-06-17 18:03:47,879: training iter 143, dice_loss=0.7259142398834229, lr=7.105427198782324e-17 (10.681236s)
INFO:niftynet:2019-06-17 18:03:58,602: training iter 144, dice_loss=0.7114966511726379, lr=3.552713599391162e-17 (10.722579s)
INFO:niftynet:2019-06-17 18:04:08,288: training iter 145, dice_loss=0.6916870474815369, lr=3.552713599391162e-17 (9.685508s)
INFO:niftynet:2019-06-17 18:04:17,730: training iter 146, dice_loss=0.7128769755363464, lr=3.552713599391162e-17 (9.442235s)
INFO:niftynet:2019-06-17 18:04:27,999: training iter 147, dice_loss=0.6896293759346008, lr=1.776356799695581e-17 (10.268031s)
INFO:niftynet:2019-06-17 18:04:39,983: training iter 148, dice_loss=0.7054324150085449, lr=1.776356799695581e-17 (11.957901s)
INFO:niftynet:2019-06-17 18:04:49,548: training iter 149, dice_loss=0.6905238032341003, lr=1.776356799695581e-17 (9.564123s)
INFO:niftynet:2019-06-17 18:05:01,216: iter 150 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 18:05:01,228: training iter 150, dice_loss=0.7143034934997559, lr=8.881783998477905e-18 (9.890560s)
INFO:niftynet:2019-06-17 18:05:11,140: training iter 151, dice_loss=0.7125312685966492, lr=8.881783998477905e-18 (9.896503s)
INFO:niftynet:2019-06-17 18:05:21,233: training iter 152, dice_loss=0.6874725222587585, lr=8.881783998477905e-18 (10.092278s)
INFO:niftynet:2019-06-17 18:05:31,155: training iter 153, dice_loss=0.6859278678894043, lr=4.440891999238953e-18 (9.921782s)
INFO:niftynet:2019-06-17 18:05:41,932: training iter 154, dice_loss=0.6960234045982361, lr=4.440891999238953e-18 (10.776263s)
INFO:niftynet:2019-06-17 18:05:53,362: training iter 155, dice_loss=0.6918930411338806, lr=4.440891999238953e-18 (11.429065s)
INFO:niftynet:2019-06-17 18:06:02,910: training iter 156, dice_loss=0.6901885867118835, lr=2.2204459996194763e-18 (9.548002s)
INFO:niftynet:2019-06-17 18:06:12,865: training iter 157, dice_loss=0.6986799240112305, lr=2.2204459996194763e-18 (9.955179s)
INFO:niftynet:2019-06-17 18:06:23,092: training iter 158, dice_loss=0.6944474577903748, lr=2.2204459996194763e-18 (10.226565s)
INFO:niftynet:2019-06-17 18:06:32,414: training iter 159, dice_loss=0.6937026977539062, lr=1.1102229998097382e-18 (9.321176s)
INFO:niftynet:2019-06-17 18:06:42,368: training iter 160, dice_loss=0.702549934387207, lr=1.1102229998097382e-18 (9.941257s)
INFO:niftynet:2019-06-17 18:06:51,836: training iter 161, dice_loss=0.6973679661750793, lr=1.1102229998097382e-18 (9.441893s)
INFO:niftynet:2019-06-17 18:07:02,548: training iter 162, dice_loss=0.7008112072944641, lr=5.551114999048691e-19 (10.711070s)
INFO:niftynet:2019-06-17 18:07:14,112: training iter 163, dice_loss=0.6975669860839844, lr=5.551114999048691e-19 (11.563880s)
INFO:niftynet:2019-06-17 18:07:23,666: training iter 164, dice_loss=0.6922085881233215, lr=5.551114999048691e-19 (9.553506s)
INFO:niftynet:2019-06-17 18:07:33,610: training iter 165, dice_loss=0.694589376449585, lr=2.7755574995243454e-19 (9.943626s)
INFO:niftynet:2019-06-17 18:07:44,417: training iter 166, dice_loss=0.6984395980834961, lr=2.7755574995243454e-19 (10.805784s)
INFO:niftynet:2019-06-17 18:07:54,042: training iter 167, dice_loss=0.6907057762145996, lr=2.7755574995243454e-19 (9.624450s)
INFO:niftynet:2019-06-17 18:08:03,776: training iter 168, dice_loss=0.6978044509887695, lr=1.3877787497621727e-19 (9.729170s)
INFO:niftynet:2019-06-17 18:08:14,139: training iter 169, dice_loss=0.699928343296051, lr=1.3877787497621727e-19 (10.362362s)
INFO:niftynet:2019-06-17 18:08:26,493: training iter 170, dice_loss=0.7021049857139587, lr=1.3877787497621727e-19 (12.331813s)
INFO:niftynet:2019-06-17 18:08:35,782: training iter 171, dice_loss=0.7055044174194336, lr=6.938893748810864e-20 (9.272747s)
INFO:niftynet:2019-06-17 18:08:45,841: training iter 172, dice_loss=0.6877257823944092, lr=6.938893748810864e-20 (10.058651s)
INFO:niftynet:2019-06-17 18:08:57,180: training iter 173, dice_loss=0.7168452143669128, lr=6.938893748810864e-20 (11.338709s)
INFO:niftynet:2019-06-17 18:09:06,590: training iter 174, dice_loss=0.6960022449493408, lr=3.469446874405432e-20 (9.409932s)
INFO:niftynet:2019-06-17 18:09:17,974: iter 175 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 18:09:17,976: training iter 175, dice_loss=0.7112794518470764, lr=3.469446874405432e-20 (9.358321s)
INFO:niftynet:2019-06-17 18:09:28,032: training iter 176, dice_loss=0.7112770676612854, lr=3.469446874405432e-20 (10.055510s)
INFO:niftynet:2019-06-17 18:09:38,259: training iter 177, dice_loss=0.7198970913887024, lr=1.734723437202716e-20 (10.226481s)
INFO:niftynet:2019-06-17 18:09:47,620: training iter 178, dice_loss=0.70291668176651, lr=1.734723437202716e-20 (9.359837s)
INFO:niftynet:2019-06-17 18:09:57,157: training iter 179, dice_loss=0.6917386054992676, lr=1.734723437202716e-20 (9.536724s)
INFO:niftynet:2019-06-17 18:10:07,917: training iter 180, dice_loss=0.7077779173851013, lr=8.67361718601358e-21 (10.750869s)
INFO:niftynet:2019-06-17 18:10:19,076: training iter 181, dice_loss=0.6999227404594421, lr=8.67361718601358e-21 (11.144018s)
INFO:niftynet:2019-06-17 18:10:28,273: training iter 182, dice_loss=0.6942651867866516, lr=8.67361718601358e-21 (9.196410s)
INFO:niftynet:2019-06-17 18:10:38,043: training iter 183, dice_loss=0.6863115429878235, lr=4.33680859300679e-21 (9.769766s)
INFO:niftynet:2019-06-17 18:10:47,975: training iter 184, dice_loss=0.7156054377555847, lr=4.33680859300679e-21 (9.931708s)
INFO:niftynet:2019-06-17 18:11:00,337: training iter 185, dice_loss=0.70672607421875, lr=4.33680859300679e-21 (12.361350s)
INFO:niftynet:2019-06-17 18:11:09,747: training iter 186, dice_loss=0.7181703448295593, lr=2.168404296503395e-21 (9.403387s)
INFO:niftynet:2019-06-17 18:11:19,562: training iter 187, dice_loss=0.6821956634521484, lr=2.168404296503395e-21 (9.814087s)
INFO:niftynet:2019-06-17 18:11:29,523: training iter 188, dice_loss=0.6941758990287781, lr=2.168404296503395e-21 (9.960995s)
INFO:niftynet:2019-06-17 18:11:41,707: training iter 189, dice_loss=0.7111880779266357, lr=1.0842021482516974e-21 (12.183494s)
INFO:niftynet:2019-06-17 18:11:51,488: training iter 190, dice_loss=0.7106590270996094, lr=1.0842021482516974e-21 (9.765372s)
INFO:niftynet:2019-06-17 18:12:01,394: training iter 191, dice_loss=0.7093145251274109, lr=1.0842021482516974e-21 (9.905145s)
INFO:niftynet:2019-06-17 18:12:11,703: training iter 192, dice_loss=0.6832035183906555, lr=5.421010741258487e-22 (10.308803s)
INFO:niftynet:2019-06-17 18:12:21,077: training iter 193, dice_loss=0.6827090382575989, lr=5.421010741258487e-22 (9.373666s)
INFO:niftynet:2019-06-17 18:12:30,472: training iter 194, dice_loss=0.698600709438324, lr=5.421010741258487e-22 (9.394968s)
INFO:niftynet:2019-06-17 18:12:41,549: training iter 195, dice_loss=0.7088512778282166, lr=2.7105053706292436e-22 (11.075380s)
INFO:niftynet:2019-06-17 18:12:50,278: training iter 196, dice_loss=0.7195766568183899, lr=2.7105053706292436e-22 (8.729344s)
INFO:niftynet:2019-06-17 18:13:00,586: training iter 197, dice_loss=0.708810031414032, lr=2.7105053706292436e-22 (10.306630s)
INFO:niftynet:2019-06-17 18:13:13,751: training iter 198, dice_loss=0.6959334015846252, lr=1.3552526853146218e-22 (13.164955s)
INFO:niftynet:2019-06-17 18:13:26,837: training iter 199, dice_loss=0.7024069428443909, lr=1.3552526853146218e-22 (13.085389s)
INFO:niftynet:2019-06-17 18:13:39,816: iter 200 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 18:13:39,824: training iter 200, dice_loss=0.6914145350456238, lr=1.3552526853146218e-22 (10.189660s)
INFO:niftynet:2019-06-17 18:13:49,230: training iter 201, dice_loss=0.7021601796150208, lr=6.776263426573109e-23 (9.392158s)
INFO:niftynet:2019-06-17 18:13:59,150: training iter 202, dice_loss=0.713184654712677, lr=6.776263426573109e-23 (9.919493s)
INFO:niftynet:2019-06-17 18:14:09,512: training iter 203, dice_loss=0.6937885284423828, lr=6.776263426573109e-23 (10.361704s)
INFO:niftynet:2019-06-17 18:14:19,361: training iter 204, dice_loss=0.7356392741203308, lr=3.3881317132865545e-23 (9.848948s)
INFO:niftynet:2019-06-17 18:14:28,877: training iter 205, dice_loss=0.693962574005127, lr=3.3881317132865545e-23 (9.515464s)
INFO:niftynet:2019-06-17 18:14:38,733: training iter 206, dice_loss=0.712909996509552, lr=3.3881317132865545e-23 (9.855137s)
INFO:niftynet:2019-06-17 18:14:49,009: training iter 207, dice_loss=0.6999519467353821, lr=1.6940658566432772e-23 (10.275591s)
INFO:niftynet:2019-06-17 18:14:58,424: training iter 208, dice_loss=0.7174026370048523, lr=1.6940658566432772e-23 (9.414518s)
INFO:niftynet:2019-06-17 18:15:08,261: training iter 209, dice_loss=0.691835880279541, lr=1.6940658566432772e-23 (9.811426s)
INFO:niftynet:2019-06-17 18:15:17,988: training iter 210, dice_loss=0.7023618817329407, lr=8.470329283216386e-24 (9.716561s)
INFO:niftynet:2019-06-17 18:15:28,065: training iter 211, dice_loss=0.6940630078315735, lr=8.470329283216386e-24 (10.050648s)
INFO:niftynet:2019-06-17 18:15:37,785: training iter 212, dice_loss=0.69342041015625, lr=8.470329283216386e-24 (9.719764s)
INFO:niftynet:2019-06-17 18:15:49,459: training iter 213, dice_loss=0.697385311126709, lr=4.235164641608193e-24 (11.673960s)
INFO:niftynet:2019-06-17 18:16:02,211: training iter 214, dice_loss=0.6831056475639343, lr=4.235164641608193e-24 (12.751674s)
INFO:niftynet:2019-06-17 18:16:11,805: training iter 215, dice_loss=0.7195777893066406, lr=4.235164641608193e-24 (9.593757s)
INFO:niftynet:2019-06-17 18:16:21,793: training iter 216, dice_loss=0.6998798251152039, lr=2.1175823208040965e-24 (9.987681s)
INFO:niftynet:2019-06-17 18:16:31,935: training iter 217, dice_loss=0.6903245449066162, lr=2.1175823208040965e-24 (10.122426s)
INFO:niftynet:2019-06-17 18:16:42,015: training iter 218, dice_loss=0.7160934805870056, lr=2.1175823208040965e-24 (10.079270s)
INFO:niftynet:2019-06-17 18:16:51,711: training iter 219, dice_loss=0.7213668823242188, lr=1.0587911604020483e-24 (9.695549s)
INFO:niftynet:2019-06-17 18:17:01,510: training iter 220, dice_loss=0.7026422619819641, lr=1.0587911604020483e-24 (9.790488s)
INFO:niftynet:2019-06-17 18:17:12,850: training iter 221, dice_loss=0.7169988751411438, lr=1.0587911604020483e-24 (11.321785s)
INFO:niftynet:2019-06-17 18:17:22,220: training iter 222, dice_loss=0.689244270324707, lr=5.293955802010241e-25 (9.370093s)
INFO:niftynet:2019-06-17 18:17:32,220: training iter 223, dice_loss=0.6831737160682678, lr=5.293955802010241e-25 (9.999480s)
INFO:niftynet:2019-06-17 18:17:43,565: training iter 224, dice_loss=0.6926066875457764, lr=5.293955802010241e-25 (11.344729s)
INFO:niftynet:2019-06-17 18:17:55,959: iter 225 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 18:17:55,959: training iter 225, dice_loss=0.7129416465759277, lr=2.6469779010051207e-25 (10.012632s)
INFO:niftynet:2019-06-17 18:18:05,069: training iter 226, dice_loss=0.7122425436973572, lr=2.6469779010051207e-25 (9.109781s)
INFO:niftynet:2019-06-17 18:18:14,261: training iter 227, dice_loss=0.7000167369842529, lr=2.6469779010051207e-25 (9.191196s)
INFO:niftynet:2019-06-17 18:18:25,211: training iter 228, dice_loss=0.7027156352996826, lr=1.3234889505025603e-25 (10.950062s)
INFO:niftynet:2019-06-17 18:18:34,608: training iter 229, dice_loss=0.7044455409049988, lr=1.3234889505025603e-25 (9.396768s)
INFO:niftynet:2019-06-17 18:18:44,107: training iter 230, dice_loss=0.6945281028747559, lr=1.3234889505025603e-25 (9.490084s)
INFO:niftynet:2019-06-17 18:18:54,272: training iter 231, dice_loss=0.6906148791313171, lr=6.617444752512802e-26 (10.149161s)
INFO:niftynet:2019-06-17 18:19:05,273: training iter 232, dice_loss=0.696273148059845, lr=6.617444752512802e-26 (11.000101s)
INFO:niftynet:2019-06-17 18:19:15,029: training iter 233, dice_loss=0.6842277646064758, lr=6.617444752512802e-26 (9.755718s)
INFO:niftynet:2019-06-17 18:19:24,925: training iter 234, dice_loss=0.6897673606872559, lr=3.308722376256401e-26 (9.895835s)
INFO:niftynet:2019-06-17 18:19:36,843: training iter 235, dice_loss=0.693342924118042, lr=3.308722376256401e-26 (11.918103s)
INFO:niftynet:2019-06-17 18:19:46,485: training iter 236, dice_loss=0.6961221098899841, lr=3.308722376256401e-26 (9.641105s)
INFO:niftynet:2019-06-17 18:19:56,185: training iter 237, dice_loss=0.6951157450675964, lr=1.6543611881282004e-26 (9.699824s)
INFO:niftynet:2019-06-17 18:20:05,931: training iter 238, dice_loss=0.7034778594970703, lr=1.6543611881282004e-26 (9.745465s)
INFO:niftynet:2019-06-17 18:20:18,899: training iter 239, dice_loss=0.712193489074707, lr=1.6543611881282004e-26 (12.967469s)
INFO:niftynet:2019-06-17 18:20:28,568: training iter 240, dice_loss=0.7054123878479004, lr=8.271805940641002e-27 (9.632731s)
INFO:niftynet:2019-06-17 18:20:37,912: training iter 241, dice_loss=0.7110897898674011, lr=8.271805940641002e-27 (9.324343s)
INFO:niftynet:2019-06-17 18:20:48,086: training iter 242, dice_loss=0.6997418403625488, lr=8.271805940641002e-27 (10.173292s)
INFO:niftynet:2019-06-17 18:20:59,163: training iter 243, dice_loss=0.7101557850837708, lr=4.135902970320501e-27 (11.076931s)
INFO:niftynet:2019-06-17 18:21:08,851: training iter 244, dice_loss=0.6889336705207825, lr=4.135902970320501e-27 (9.687738s)
INFO:niftynet:2019-06-17 18:21:19,019: training iter 245, dice_loss=0.6823856830596924, lr=4.135902970320501e-27 (10.166503s)
INFO:niftynet:2019-06-17 18:21:29,499: training iter 246, dice_loss=0.6966750621795654, lr=2.0679514851602505e-27 (10.479323s)
INFO:niftynet:2019-06-17 18:21:39,390: training iter 247, dice_loss=0.7085078358650208, lr=2.0679514851602505e-27 (9.891049s)
INFO:niftynet:2019-06-17 18:21:48,930: training iter 248, dice_loss=0.6980549693107605, lr=2.0679514851602505e-27 (9.539655s)
INFO:niftynet:2019-06-17 18:21:59,447: training iter 249, dice_loss=0.6914210319519043, lr=1.0339757425801253e-27 (10.516291s)
INFO:niftynet:2019-06-17 18:22:13,196: iter 250 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 18:22:13,237: training iter 250, dice_loss=0.7062390446662903, lr=1.0339757425801253e-27 (11.835753s)
INFO:niftynet:2019-06-17 18:22:22,919: training iter 251, dice_loss=0.7228756546974182, lr=1.0339757425801253e-27 (9.681740s)
INFO:niftynet:2019-06-17 18:22:32,439: training iter 252, dice_loss=0.6952400207519531, lr=5.169878712900626e-28 (9.519884s)
INFO:niftynet:2019-06-17 18:22:42,337: training iter 253, dice_loss=0.6922661662101746, lr=5.169878712900626e-28 (9.897954s)
INFO:niftynet:2019-06-17 18:22:51,935: training iter 254, dice_loss=0.6917781233787537, lr=5.169878712900626e-28 (9.592167s)
INFO:niftynet:2019-06-17 18:23:01,902: training iter 255, dice_loss=0.6879048347473145, lr=2.584939356450313e-28 (9.967131s)
INFO:niftynet:2019-06-17 18:23:11,410: training iter 256, dice_loss=0.6856362223625183, lr=2.584939356450313e-28 (9.505266s)
INFO:niftynet:2019-06-17 18:23:22,277: training iter 257, dice_loss=0.7054116129875183, lr=2.584939356450313e-28 (10.866130s)
INFO:niftynet:2019-06-17 18:23:32,391: training iter 258, dice_loss=0.705430805683136, lr=1.2924696782251566e-28 (10.114006s)
INFO:niftynet:2019-06-17 18:23:42,399: training iter 259, dice_loss=0.6988784670829773, lr=1.2924696782251566e-28 (10.007293s)
INFO:niftynet:2019-06-17 18:23:52,127: training iter 260, dice_loss=0.6981856822967529, lr=1.2924696782251566e-28 (9.700134s)
INFO:niftynet:2019-06-17 18:24:04,403: training iter 261, dice_loss=0.7101936340332031, lr=6.462348391125783e-29 (12.251936s)
INFO:niftynet:2019-06-17 18:24:14,328: training iter 262, dice_loss=0.6937875747680664, lr=6.462348391125783e-29 (9.924848s)
INFO:niftynet:2019-06-17 18:24:23,880: training iter 263, dice_loss=0.7115421891212463, lr=6.462348391125783e-29 (9.551855s)
INFO:niftynet:2019-06-17 18:24:31,634: training iter 264, dice_loss=0.6869456171989441, lr=3.2311741955628914e-29 (7.753465s)
INFO:niftynet:2019-06-17 18:24:49,762: training iter 265, dice_loss=0.6971765160560608, lr=3.2311741955628914e-29 (18.127626s)
INFO:niftynet:2019-06-17 18:24:58,868: training iter 266, dice_loss=0.7020173668861389, lr=3.2311741955628914e-29 (9.105030s)
INFO:niftynet:2019-06-17 18:25:08,660: training iter 267, dice_loss=0.7018209099769592, lr=1.6155870977814457e-29 (9.792222s)
INFO:niftynet:2019-06-17 18:25:18,577: training iter 268, dice_loss=0.7056775093078613, lr=1.6155870977814457e-29 (9.916517s)
INFO:niftynet:2019-06-17 18:25:27,985: training iter 269, dice_loss=0.687216579914093, lr=1.6155870977814457e-29 (9.406997s)
INFO:niftynet:2019-06-17 18:25:37,673: training iter 270, dice_loss=0.6875564455986023, lr=8.077935488907229e-30 (9.661354s)
INFO:niftynet:2019-06-17 18:25:47,932: training iter 271, dice_loss=0.708311140537262, lr=8.077935488907229e-30 (10.258942s)
INFO:niftynet:2019-06-17 18:25:57,389: training iter 272, dice_loss=0.7040960192680359, lr=8.077935488907229e-30 (9.455788s)
INFO:niftynet:2019-06-17 18:26:07,156: training iter 273, dice_loss=0.7104358077049255, lr=4.038967744453614e-30 (9.767128s)
INFO:niftynet:2019-06-17 18:26:16,664: training iter 274, dice_loss=0.6986514925956726, lr=4.038967744453614e-30 (9.507629s)
INFO:niftynet:2019-06-17 18:26:29,865: iter 275 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 18:26:29,867: training iter 275, dice_loss=0.6851019859313965, lr=4.038967744453614e-30 (10.716604s)
INFO:niftynet:2019-06-17 18:26:39,728: training iter 276, dice_loss=0.7030067443847656, lr=2.019483872226807e-30 (9.860931s)
INFO:niftynet:2019-06-17 18:26:49,309: training iter 277, dice_loss=0.6948607563972473, lr=2.019483872226807e-30 (9.580075s)
INFO:niftynet:2019-06-17 18:26:59,067: training iter 278, dice_loss=0.709709107875824, lr=2.019483872226807e-30 (9.757784s)
INFO:niftynet:2019-06-17 18:27:10,355: training iter 279, dice_loss=0.7066974639892578, lr=1.0097419361134036e-30 (11.287822s)
INFO:niftynet:2019-06-17 18:27:19,688: training iter 280, dice_loss=0.7037801742553711, lr=1.0097419361134036e-30 (9.319539s)
INFO:niftynet:2019-06-17 18:27:29,427: training iter 281, dice_loss=0.697836697101593, lr=1.0097419361134036e-30 (9.725692s)
INFO:niftynet:2019-06-17 18:27:39,514: training iter 282, dice_loss=0.6984688639640808, lr=5.048709680567018e-31 (10.087379s)
INFO:niftynet:2019-06-17 18:27:50,060: training iter 283, dice_loss=0.7091638445854187, lr=5.048709680567018e-31 (10.545377s)
INFO:niftynet:2019-06-17 18:27:59,620: training iter 284, dice_loss=0.6967141032218933, lr=5.048709680567018e-31 (9.558015s)
INFO:niftynet:2019-06-17 18:28:08,803: training iter 285, dice_loss=0.6815571784973145, lr=2.524354840283509e-31 (9.182941s)
INFO:niftynet:2019-06-17 18:28:18,698: training iter 286, dice_loss=0.6929371356964111, lr=2.524354840283509e-31 (9.895066s)
INFO:niftynet:2019-06-17 18:28:29,832: training iter 287, dice_loss=0.6921525001525879, lr=2.524354840283509e-31 (11.133163s)
INFO:niftynet:2019-06-17 18:28:39,600: training iter 288, dice_loss=0.7081049084663391, lr=1.2621774201417545e-31 (9.767558s)
INFO:niftynet:2019-06-17 18:28:50,266: training iter 289, dice_loss=0.6987054347991943, lr=1.2621774201417545e-31 (10.665697s)
INFO:niftynet:2019-06-17 18:29:00,334: training iter 290, dice_loss=0.725964367389679, lr=1.2621774201417545e-31 (10.051050s)
INFO:niftynet:2019-06-17 18:29:10,986: training iter 291, dice_loss=0.7059879302978516, lr=6.310887100708772e-32 (10.616621s)
INFO:niftynet:2019-06-17 18:29:20,733: training iter 292, dice_loss=0.7077812552452087, lr=6.310887100708772e-32 (9.746532s)
INFO:niftynet:2019-06-17 18:29:30,720: training iter 293, dice_loss=0.6910513043403625, lr=6.310887100708772e-32 (9.987392s)
INFO:niftynet:2019-06-17 18:29:40,788: training iter 294, dice_loss=0.6856400370597839, lr=3.155443550354386e-32 (10.066843s)
INFO:niftynet:2019-06-17 18:29:50,733: training iter 295, dice_loss=0.7035624384880066, lr=3.155443550354386e-32 (9.944761s)
INFO:niftynet:2019-06-17 18:30:02,189: training iter 296, dice_loss=0.7244641184806824, lr=3.155443550354386e-32 (11.456167s)
INFO:niftynet:2019-06-17 18:30:13,658: training iter 297, dice_loss=0.6864460110664368, lr=1.577721775177193e-32 (11.468081s)
INFO:niftynet:2019-06-17 18:30:23,131: training iter 298, dice_loss=0.7097702622413635, lr=1.577721775177193e-32 (9.472529s)
INFO:niftynet:2019-06-17 18:30:32,523: training iter 299, dice_loss=0.6883696913719177, lr=1.577721775177193e-32 (9.391841s)
INFO:niftynet:2019-06-17 18:30:44,181: iter 300 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 18:30:44,225: training iter 300, dice_loss=0.6932685375213623, lr=7.888608875885965e-33 (9.236368s)
INFO:niftynet:2019-06-17 18:30:53,765: training iter 301, dice_loss=0.6913261413574219, lr=7.888608875885965e-33 (9.520921s)
INFO:niftynet:2019-06-17 18:31:03,714: training iter 302, dice_loss=0.6942651271820068, lr=7.888608875885965e-33 (9.948152s)
INFO:niftynet:2019-06-17 18:31:14,223: training iter 303, dice_loss=0.6835413575172424, lr=3.944304437942983e-33 (10.509160s)
INFO:niftynet:2019-06-17 18:31:24,309: training iter 304, dice_loss=0.7019124627113342, lr=3.944304437942983e-33 (10.085017s)
INFO:niftynet:2019-06-17 18:31:33,357: training iter 305, dice_loss=0.7035042643547058, lr=3.944304437942983e-33 (9.048018s)
INFO:niftynet:2019-06-17 18:31:43,080: training iter 306, dice_loss=0.7008212208747864, lr=1.9721522189714914e-33 (9.719713s)
INFO:niftynet:2019-06-17 18:31:54,085: training iter 307, dice_loss=0.7272189259529114, lr=1.9721522189714914e-33 (11.003929s)
INFO:niftynet:2019-06-17 18:32:04,469: training iter 308, dice_loss=0.7015379071235657, lr=1.9721522189714914e-33 (10.384284s)
INFO:niftynet:2019-06-17 18:32:13,512: training iter 309, dice_loss=0.6951126456260681, lr=9.860761094857457e-34 (9.042492s)
INFO:niftynet:2019-06-17 18:32:23,537: training iter 310, dice_loss=0.6943861842155457, lr=9.860761094857457e-34 (10.014714s)
INFO:niftynet:2019-06-17 18:32:33,520: training iter 311, dice_loss=0.7058355212211609, lr=9.860761094857457e-34 (9.946549s)
INFO:niftynet:2019-06-17 18:32:45,031: training iter 312, dice_loss=0.6868732571601868, lr=4.930380547428728e-34 (11.510595s)
INFO:niftynet:2019-06-17 18:32:54,530: training iter 313, dice_loss=0.6930798888206482, lr=4.930380547428728e-34 (9.498945s)
INFO:niftynet:2019-06-17 18:33:04,576: training iter 314, dice_loss=0.6988508105278015, lr=4.930380547428728e-34 (10.045768s)
INFO:niftynet:2019-06-17 18:33:13,292: training iter 315, dice_loss=0.687548816204071, lr=2.465190273714364e-34 (8.715084s)
INFO:niftynet:2019-06-17 18:33:24,641: training iter 316, dice_loss=0.7024819254875183, lr=2.465190273714364e-34 (11.349184s)
INFO:niftynet:2019-06-17 18:33:34,808: training iter 317, dice_loss=0.7180090546607971, lr=2.465190273714364e-34 (10.166067s)
INFO:niftynet:2019-06-17 18:33:46,525: training iter 318, dice_loss=0.6906670928001404, lr=1.232595136857182e-34 (11.717117s)
INFO:niftynet:2019-06-17 18:33:56,224: training iter 319, dice_loss=0.6882160305976868, lr=1.232595136857182e-34 (9.698496s)
INFO:niftynet:2019-06-17 18:34:06,214: training iter 320, dice_loss=0.6980552673339844, lr=1.232595136857182e-34 (9.968980s)
INFO:niftynet:2019-06-17 18:34:16,773: training iter 321, dice_loss=0.6930801272392273, lr=6.16297568428591e-35 (10.536096s)
