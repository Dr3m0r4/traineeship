INFO:niftynet:2019-06-06 14:54:10,330: set CUDA_VISIBLE_DEVICES to 0
INFO:niftynet:2019-06-06 14:54:10,330: starting segmentation application
INFO:niftynet:2019-06-06 14:54:10,330: `csv_file = ` not found, writing to "/home/julien/traineeship/mmiv/model/image.csv" instead.
INFO:niftynet:2019-06-06 14:54:10,330: [image] search file folders, writing csv file /home/julien/traineeship/mmiv/model/image.csv
INFO:niftynet:2019-06-06 14:54:10,363: `csv_file = ` not found, writing to "/home/julien/traineeship/mmiv/model/label.csv" instead.
INFO:niftynet:2019-06-06 14:54:10,363: [label] search file folders, writing csv file /home/julien/traineeship/mmiv/model/label.csv
INFO:niftynet:2019-06-06 14:54:10,400: 

Number of subjects 581, input section names: ['subject_id', 'image', 'label']
Dataset partitioning:
-- training 406 cases (69.88%),
-- validation 0 cases (0.00%),
-- inference 175 cases (30.12%).

INFO:niftynet:2019-06-06 14:54:12,409: Image reader: loading 406 subjects from sections ('image',) as input [image]
INFO:niftynet:2019-06-06 14:54:12,409: Image reader: loading 406 subjects from sections ('label',) as input [label]
INFO:niftynet:2019-06-06 14:54:12,410: label mapping ready for label:('label',), 2 classes
INFO:niftynet:2019-06-06 14:54:12,587: initialised uniform sampler {'image': (1, 144, 144, 144, 1, 1), 'image_location': (1, 7), 'label': (1, 144, 144, 144, 1, 1), 'label_location': (1, 7)} 
WARNING:niftynet:2019-06-06 14:54:12,590: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/engine/application_initializer.py:106: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.
Instructions for updating:
`normal` is a deprecated alias for `truncated_normal`
INFO:niftynet:2019-06-06 14:54:12,590: using DenseVNet
INFO:niftynet:2019-06-06 14:54:12,593: Initialising Dataset from 406 subjects...
WARNING:niftynet:2019-06-06 14:54:12,596: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/engine/image_window_dataset.py:300: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, use
    tf.py_function, which takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    
WARNING:niftynet:2019-06-06 14:54:12,767: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/grid_warper.py:291: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-06 14:54:13,858: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:niftynet:2019-06-06 14:54:14,094: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/activation.py:68: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:niftynet:2019-06-06 14:54:16,136: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/loss_segmentation.py:157: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-06 14:54:16,142: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/loss_segmentation.py:174: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-06 14:54:16,152: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: calling sparse_reduce_sum (from tensorflow.python.ops.sparse_ops) with reduction_axes is deprecated and will be removed in a future version.
Instructions for updating:
reduction_axes is deprecated, use axis instead
INFO:niftynet:2019-06-06 14:54:27,016: Parameters from random initialisations ...
INFO:niftynet:2019-06-06 14:56:09,549: training iter 1, loss=0.3451857566833496 (102.532625s)
INFO:niftynet:2019-06-06 14:56:18,909: training iter 2, loss=0.19131088256835938 (9.359326s)
INFO:niftynet:2019-06-06 14:56:29,238: training iter 3, loss=0.17441292107105255 (10.329377s)
INFO:niftynet:2019-06-06 14:56:41,822: training iter 4, loss=0.19222252070903778 (12.582992s)
INFO:niftynet:2019-06-06 14:56:50,749: training iter 5, loss=0.13606880605220795 (8.926590s)
INFO:niftynet:2019-06-06 14:57:00,844: training iter 6, loss=0.14870889484882355 (10.095259s)
INFO:niftynet:2019-06-06 14:57:12,931: training iter 7, loss=0.1237177774310112 (12.085929s)
INFO:niftynet:2019-06-06 14:57:28,435: training iter 8, loss=0.1379057914018631 (15.504046s)
INFO:niftynet:2019-06-06 14:57:37,553: training iter 9, loss=0.11561552435159683 (9.107501s)
INFO:niftynet:2019-06-06 14:58:03,702: training iter 10, loss=0.14635735750198364 (26.148240s)
INFO:niftynet:2019-06-06 14:58:13,244: training iter 11, loss=0.10253843665122986 (9.526673s)
INFO:niftynet:2019-06-06 14:58:23,254: training iter 12, loss=0.13294045627117157 (10.009206s)
INFO:niftynet:2019-06-06 14:58:32,800: training iter 13, loss=0.1318257600069046 (9.545385s)
INFO:niftynet:2019-06-06 14:58:41,837: training iter 14, loss=0.10787072777748108 (9.036928s)
INFO:niftynet:2019-06-06 14:58:51,445: training iter 15, loss=0.10218163579702377 (9.607456s)
INFO:niftynet:2019-06-06 14:59:01,184: training iter 16, loss=0.11145702004432678 (9.738770s)
INFO:niftynet:2019-06-06 14:59:11,294: training iter 17, loss=0.1276288479566574 (10.106551s)
INFO:niftynet:2019-06-06 14:59:21,782: training iter 18, loss=0.10403523594141006 (10.487463s)
INFO:niftynet:2019-06-06 14:59:31,339: training iter 19, loss=0.08093004673719406 (9.556537s)
INFO:niftynet:2019-06-06 14:59:43,723: training iter 20, loss=0.09324754029512405 (12.384263s)
INFO:niftynet:2019-06-06 14:59:57,245: training iter 21, loss=0.15955543518066406 (13.505973s)
INFO:niftynet:2019-06-06 15:00:07,114: training iter 22, loss=0.09436076134443283 (9.868429s)
INFO:niftynet:2019-06-06 15:00:18,844: training iter 23, loss=0.12144722789525986 (11.729022s)
INFO:niftynet:2019-06-06 15:00:30,360: training iter 24, loss=0.08940482139587402 (11.516277s)
INFO:niftynet:2019-06-06 15:00:41,680: training iter 25, loss=0.12476786226034164 (11.319502s)
INFO:niftynet:2019-06-06 15:00:44,690: iter 25 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:00:54,542: training iter 26, loss=0.10118696093559265 (9.851636s)
INFO:niftynet:2019-06-06 15:01:05,563: training iter 27, loss=0.09175754338502884 (11.020448s)
INFO:niftynet:2019-06-06 15:01:17,159: training iter 28, loss=0.09007397294044495 (11.595730s)
INFO:niftynet:2019-06-06 15:01:27,908: training iter 29, loss=0.07619764655828476 (10.747894s)
INFO:niftynet:2019-06-06 15:01:42,130: training iter 30, loss=0.10045009106397629 (14.222042s)
INFO:niftynet:2019-06-06 15:01:51,781: training iter 31, loss=0.08345159143209457 (9.617518s)
INFO:niftynet:2019-06-06 15:02:01,517: training iter 32, loss=0.11040858179330826 (9.736215s)
INFO:niftynet:2019-06-06 15:02:16,583: training iter 33, loss=0.08006724715232849 (15.065069s)
INFO:niftynet:2019-06-06 15:02:28,232: training iter 34, loss=0.07226136326789856 (11.648971s)
INFO:niftynet:2019-06-06 15:02:37,759: training iter 35, loss=0.08557158708572388 (9.526593s)
INFO:niftynet:2019-06-06 15:02:49,045: training iter 36, loss=0.08942220360040665 (11.286060s)
INFO:niftynet:2019-06-06 15:03:02,169: training iter 37, loss=0.08275420218706131 (13.123307s)
INFO:niftynet:2019-06-06 15:03:12,223: training iter 38, loss=0.08178457617759705 (10.053121s)
INFO:niftynet:2019-06-06 15:03:21,765: training iter 39, loss=0.07672321051359177 (9.541817s)
INFO:niftynet:2019-06-06 15:03:35,538: training iter 40, loss=0.1030048057436943 (13.772997s)
INFO:niftynet:2019-06-06 15:03:50,222: training iter 41, loss=0.08050919324159622 (14.649549s)
INFO:niftynet:2019-06-06 15:03:59,721: training iter 42, loss=0.07053656131029129 (9.477930s)
INFO:niftynet:2019-06-06 15:04:09,770: training iter 43, loss=0.07205191999673843 (10.048983s)
INFO:niftynet:2019-06-06 15:04:23,887: training iter 44, loss=0.07421793788671494 (14.116534s)
INFO:niftynet:2019-06-06 15:04:34,255: training iter 45, loss=0.06980347633361816 (10.367769s)
INFO:niftynet:2019-06-06 15:04:44,224: training iter 46, loss=0.085057832300663 (9.964018s)
INFO:niftynet:2019-06-06 15:04:56,061: training iter 47, loss=0.10236269980669022 (11.836825s)
INFO:niftynet:2019-06-06 15:05:11,043: training iter 48, loss=0.07448095083236694 (14.981353s)
INFO:niftynet:2019-06-06 15:05:20,607: training iter 49, loss=0.08684676885604858 (9.563440s)
INFO:niftynet:2019-06-06 15:05:30,387: training iter 50, loss=0.07827985286712646 (9.780053s)
INFO:niftynet:2019-06-06 15:05:32,572: iter 50 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:05:44,788: training iter 51, loss=0.08654516190290451 (12.174914s)
INFO:niftynet:2019-06-06 15:05:55,358: training iter 52, loss=0.0822068378329277 (10.569795s)
INFO:niftynet:2019-06-06 15:06:05,591: training iter 53, loss=0.07626893371343613 (10.232639s)
INFO:niftynet:2019-06-06 15:06:18,679: training iter 54, loss=0.06750679016113281 (13.087074s)
INFO:niftynet:2019-06-06 15:06:31,043: training iter 55, loss=0.08170586079359055 (12.363595s)
INFO:niftynet:2019-06-06 15:06:41,111: training iter 56, loss=0.08878468722105026 (10.067837s)
INFO:niftynet:2019-06-06 15:06:51,379: training iter 57, loss=0.09900940209627151 (10.265949s)
INFO:niftynet:2019-06-06 15:07:04,319: training iter 58, loss=0.09332341700792313 (12.939016s)
INFO:niftynet:2019-06-06 15:07:16,481: training iter 59, loss=0.10456304997205734 (12.162196s)
INFO:niftynet:2019-06-06 15:07:26,259: training iter 60, loss=0.07518857717514038 (9.777603s)
INFO:niftynet:2019-06-06 15:07:34,760: training iter 61, loss=0.09232660382986069 (8.490725s)
INFO:niftynet:2019-06-06 15:07:57,038: training iter 62, loss=0.10867036134004593 (22.278162s)
INFO:niftynet:2019-06-06 15:08:05,857: training iter 63, loss=0.09174534678459167 (8.805464s)
INFO:niftynet:2019-06-06 15:08:16,181: training iter 64, loss=0.09537463635206223 (10.317998s)
INFO:niftynet:2019-06-06 15:08:29,690: training iter 65, loss=0.07626091688871384 (13.508550s)
INFO:niftynet:2019-06-06 15:08:42,117: training iter 66, loss=0.10963943600654602 (12.427034s)
INFO:niftynet:2019-06-06 15:08:52,235: training iter 67, loss=0.10017607361078262 (10.116030s)
INFO:niftynet:2019-06-06 15:09:02,991: training iter 68, loss=0.08377941697835922 (10.755944s)
INFO:niftynet:2019-06-06 15:09:18,078: training iter 69, loss=0.07642682641744614 (15.086279s)
INFO:niftynet:2019-06-06 15:09:26,828: training iter 70, loss=0.09378831833600998 (8.749788s)
INFO:niftynet:2019-06-06 15:09:36,991: training iter 71, loss=0.12144482880830765 (10.150628s)
INFO:niftynet:2019-06-06 15:09:49,389: training iter 72, loss=0.07650072127580643 (12.397022s)
INFO:niftynet:2019-06-06 15:10:02,553: training iter 73, loss=0.1121065616607666 (13.163465s)
INFO:niftynet:2019-06-06 15:10:12,628: training iter 74, loss=0.0715625062584877 (10.074728s)
INFO:niftynet:2019-06-06 15:10:24,059: training iter 75, loss=0.09771531820297241 (11.430896s)
INFO:niftynet:2019-06-06 15:10:26,335: iter 75 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:10:36,424: training iter 76, loss=0.07894757390022278 (10.088628s)
INFO:niftynet:2019-06-06 15:10:51,364: training iter 77, loss=0.06942542642354965 (14.939536s)
INFO:niftynet:2019-06-06 15:11:00,938: training iter 78, loss=0.08441369980573654 (9.573918s)
INFO:niftynet:2019-06-06 15:11:11,097: training iter 79, loss=0.08215873688459396 (10.158375s)
INFO:niftynet:2019-06-06 15:11:23,614: training iter 80, loss=0.07324042171239853 (12.517321s)
INFO:niftynet:2019-06-06 15:11:36,415: training iter 81, loss=0.09842965751886368 (12.760188s)
INFO:niftynet:2019-06-06 15:11:46,447: training iter 82, loss=0.08030170947313309 (10.031195s)
INFO:niftynet:2019-06-06 15:11:59,836: training iter 83, loss=0.0797341987490654 (13.389162s)
INFO:niftynet:2019-06-06 15:12:11,611: training iter 84, loss=0.07416835427284241 (11.774027s)
INFO:niftynet:2019-06-06 15:12:23,070: training iter 85, loss=0.07858705520629883 (11.456536s)
INFO:niftynet:2019-06-06 15:12:32,520: training iter 86, loss=0.07190682739019394 (9.449699s)
INFO:niftynet:2019-06-06 15:12:44,813: training iter 87, loss=0.07558932900428772 (12.293123s)
INFO:niftynet:2019-06-06 15:12:55,462: training iter 88, loss=0.07486719638109207 (10.648161s)
INFO:niftynet:2019-06-06 15:13:09,169: training iter 89, loss=0.07273659855127335 (13.707001s)
INFO:niftynet:2019-06-06 15:13:19,267: training iter 90, loss=0.07536551356315613 (10.097100s)
INFO:niftynet:2019-06-06 15:13:30,449: training iter 91, loss=0.07311397045850754 (11.173292s)
INFO:niftynet:2019-06-06 15:13:41,895: training iter 92, loss=0.06895509362220764 (11.446051s)
INFO:niftynet:2019-06-06 15:13:55,954: training iter 93, loss=0.07345223426818848 (14.058103s)
INFO:niftynet:2019-06-06 15:14:06,143: training iter 94, loss=0.06844624876976013 (10.178155s)
INFO:niftynet:2019-06-06 15:14:17,159: training iter 95, loss=0.08054878562688828 (11.015830s)
INFO:niftynet:2019-06-06 15:14:30,261: training iter 96, loss=0.06544791907072067 (13.101703s)
INFO:niftynet:2019-06-06 15:14:39,764: training iter 97, loss=0.07340078800916672 (9.502768s)
INFO:niftynet:2019-06-06 15:14:49,897: training iter 98, loss=0.06307157129049301 (10.117382s)
INFO:niftynet:2019-06-06 15:15:06,381: training iter 99, loss=0.08275897055864334 (16.483704s)
INFO:niftynet:2019-06-06 15:15:15,844: training iter 100, loss=0.07306282967329025 (9.461852s)
INFO:niftynet:2019-06-06 15:15:18,007: iter 100 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:15:28,257: training iter 101, loss=0.06992446631193161 (10.232517s)
INFO:niftynet:2019-06-06 15:15:39,425: training iter 102, loss=0.07635105401277542 (11.168395s)
INFO:niftynet:2019-06-06 15:15:52,312: training iter 103, loss=0.07311578840017319 (12.886795s)
INFO:niftynet:2019-06-06 15:16:01,711: training iter 104, loss=0.07455538958311081 (9.398420s)
INFO:niftynet:2019-06-06 15:16:12,391: training iter 105, loss=0.0638892650604248 (10.675883s)
INFO:niftynet:2019-06-06 15:16:26,664: training iter 106, loss=0.0639025941491127 (14.272880s)
INFO:niftynet:2019-06-06 15:16:37,696: training iter 107, loss=0.07490887492895126 (11.031709s)
INFO:niftynet:2019-06-06 15:16:47,951: training iter 108, loss=0.06422987580299377 (10.254075s)
INFO:niftynet:2019-06-06 15:17:00,319: training iter 109, loss=0.08219125121831894 (12.367615s)
INFO:niftynet:2019-06-06 15:17:15,185: training iter 110, loss=0.06563209742307663 (14.866157s)
INFO:niftynet:2019-06-06 15:17:25,069: training iter 111, loss=0.062205541878938675 (9.865959s)
INFO:niftynet:2019-06-06 15:17:34,975: training iter 112, loss=0.07298051565885544 (9.905160s)
INFO:niftynet:2019-06-06 15:17:49,679: training iter 113, loss=0.10035537928342819 (14.703804s)
INFO:niftynet:2019-06-06 15:18:04,267: training iter 114, loss=0.0763414204120636 (14.587736s)
INFO:niftynet:2019-06-06 15:18:13,874: training iter 115, loss=0.07738393545150757 (9.606188s)
INFO:niftynet:2019-06-06 15:18:24,412: training iter 116, loss=0.06628481298685074 (10.536695s)
INFO:niftynet:2019-06-06 15:18:39,715: training iter 117, loss=0.0693880245089531 (15.302674s)
INFO:niftynet:2019-06-06 15:18:49,135: training iter 118, loss=0.08848490566015244 (9.419778s)
INFO:niftynet:2019-06-06 15:18:59,345: training iter 119, loss=0.0690225288271904 (10.168978s)
INFO:niftynet:2019-06-06 15:19:12,675: training iter 120, loss=0.06905052810907364 (13.330192s)
INFO:niftynet:2019-06-06 15:19:28,901: training iter 121, loss=0.06565327197313309 (16.216307s)
INFO:niftynet:2019-06-06 15:19:38,119: training iter 122, loss=0.07026245445013046 (9.217593s)
INFO:niftynet:2019-06-06 15:19:48,205: training iter 123, loss=0.09461689740419388 (10.085440s)
INFO:niftynet:2019-06-06 15:20:01,044: training iter 124, loss=0.07077985256910324 (12.838042s)
INFO:niftynet:2019-06-06 15:20:14,746: training iter 125, loss=0.08111464977264404 (13.679881s)
INFO:niftynet:2019-06-06 15:20:17,448: iter 125 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:20:26,801: training iter 126, loss=0.07312382012605667 (9.352413s)
INFO:niftynet:2019-06-06 15:20:36,967: training iter 127, loss=0.06970836967229843 (10.164868s)
INFO:niftynet:2019-06-06 15:20:47,515: training iter 128, loss=0.07576695084571838 (10.547423s)
INFO:niftynet:2019-06-06 15:20:57,394: training iter 129, loss=0.06623217463493347 (9.879388s)
INFO:niftynet:2019-06-06 15:21:15,922: training iter 130, loss=0.06569436937570572 (18.526832s)
INFO:niftynet:2019-06-06 15:21:28,389: training iter 131, loss=0.06414829939603806 (12.446982s)
INFO:niftynet:2019-06-06 15:21:38,161: training iter 132, loss=0.0670786127448082 (9.771687s)
INFO:niftynet:2019-06-06 15:21:48,849: training iter 133, loss=0.06747425347566605 (10.687952s)
INFO:niftynet:2019-06-06 15:22:00,727: training iter 134, loss=0.06443861126899719 (11.877901s)
INFO:niftynet:2019-06-06 15:22:15,568: training iter 135, loss=0.06950325518846512 (14.840288s)
INFO:niftynet:2019-06-06 15:22:25,500: training iter 136, loss=0.06395155191421509 (9.931718s)
INFO:niftynet:2019-06-06 15:22:35,921: training iter 137, loss=0.06336601823568344 (10.421062s)
INFO:niftynet:2019-06-06 15:22:50,797: training iter 138, loss=0.07198858261108398 (14.875119s)
INFO:niftynet:2019-06-06 15:23:01,020: training iter 139, loss=0.08343550562858582 (10.222527s)
INFO:niftynet:2019-06-06 15:23:11,275: training iter 140, loss=0.06279131025075912 (10.254764s)
INFO:niftynet:2019-06-06 15:23:26,047: training iter 141, loss=0.11226162314414978 (14.742889s)
INFO:niftynet:2019-06-06 15:23:35,293: training iter 142, loss=0.06514059752225876 (9.245742s)
INFO:niftynet:2019-06-06 15:23:45,225: training iter 143, loss=0.07110181450843811 (9.932316s)
INFO:niftynet:2019-06-06 15:24:01,055: training iter 144, loss=0.08440453559160233 (15.829333s)
INFO:niftynet:2019-06-06 15:24:14,399: training iter 145, loss=0.06767544895410538 (13.343817s)
INFO:niftynet:2019-06-06 15:24:23,261: training iter 146, loss=0.06646782159805298 (8.860895s)
INFO:niftynet:2019-06-06 15:24:33,234: training iter 147, loss=0.08082772046327591 (9.972514s)
INFO:niftynet:2019-06-06 15:24:47,765: training iter 148, loss=0.07341840863227844 (14.531267s)
INFO:niftynet:2019-06-06 15:24:57,751: training iter 149, loss=0.07004415988922119 (9.985130s)
INFO:niftynet:2019-06-06 15:25:07,824: training iter 150, loss=0.08807573467493057 (10.071763s)
INFO:niftynet:2019-06-06 15:25:09,972: iter 150 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:25:21,512: training iter 151, loss=0.06899875402450562 (11.530266s)
INFO:niftynet:2019-06-06 15:25:36,462: training iter 152, loss=0.05832076072692871 (14.950361s)
INFO:niftynet:2019-06-06 15:25:44,990: training iter 153, loss=0.06826213002204895 (8.527160s)
INFO:niftynet:2019-06-06 15:25:55,679: training iter 154, loss=0.07852885127067566 (10.687412s)
INFO:niftynet:2019-06-06 15:26:08,133: training iter 155, loss=0.07505130767822266 (12.453604s)
INFO:niftynet:2019-06-06 15:26:19,410: training iter 156, loss=0.0761217251420021 (11.276842s)
INFO:niftynet:2019-06-06 15:26:29,289: training iter 157, loss=0.07238298654556274 (9.863873s)
INFO:niftynet:2019-06-06 15:26:41,534: training iter 158, loss=0.08140040189027786 (12.245191s)
INFO:niftynet:2019-06-06 15:26:55,053: training iter 159, loss=0.06614089757204056 (13.518543s)
INFO:niftynet:2019-06-06 15:27:04,572: training iter 160, loss=0.07314661145210266 (9.518798s)
INFO:niftynet:2019-06-06 15:27:14,667: training iter 161, loss=0.06862330436706543 (10.052207s)
INFO:niftynet:2019-06-06 15:27:27,803: training iter 162, loss=0.06802720576524734 (13.135197s)
INFO:niftynet:2019-06-06 15:27:40,547: training iter 163, loss=0.06908708065748215 (12.743775s)
INFO:niftynet:2019-06-06 15:27:49,928: training iter 164, loss=0.07544254511594772 (9.380818s)
INFO:niftynet:2019-06-06 15:28:00,039: training iter 165, loss=0.06941436976194382 (10.110764s)
INFO:niftynet:2019-06-06 15:28:13,563: training iter 166, loss=0.06974280625581741 (13.523542s)
INFO:niftynet:2019-06-06 15:28:24,642: training iter 167, loss=0.07857060432434082 (11.078291s)
INFO:niftynet:2019-06-06 15:28:34,240: training iter 168, loss=0.06337153911590576 (9.598319s)
INFO:niftynet:2019-06-06 15:28:46,226: training iter 169, loss=0.07139724493026733 (11.985394s)
INFO:niftynet:2019-06-06 15:29:00,112: training iter 170, loss=0.07350530475378036 (13.885006s)
INFO:niftynet:2019-06-06 15:29:09,608: training iter 171, loss=0.07156989723443985 (9.456307s)
INFO:niftynet:2019-06-06 15:29:19,445: training iter 172, loss=0.0613982267677784 (9.836516s)
INFO:niftynet:2019-06-06 15:29:35,759: training iter 173, loss=0.06495111435651779 (16.314199s)
INFO:niftynet:2019-06-06 15:29:45,307: training iter 174, loss=0.059253353625535965 (9.547397s)
INFO:niftynet:2019-06-06 15:29:55,467: training iter 175, loss=0.07704364508390427 (10.159730s)
INFO:niftynet:2019-06-06 15:29:57,367: iter 175 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:30:08,827: training iter 176, loss=0.0725749060511589 (11.459661s)
INFO:niftynet:2019-06-06 15:30:22,697: training iter 177, loss=0.0694032534956932 (13.852204s)
INFO:niftynet:2019-06-06 15:30:32,171: training iter 178, loss=0.0595516674220562 (9.474047s)
INFO:niftynet:2019-06-06 15:30:41,820: training iter 179, loss=0.0688067302107811 (9.646797s)
INFO:niftynet:2019-06-06 15:30:55,514: training iter 180, loss=0.06547967344522476 (13.693892s)
INFO:niftynet:2019-06-06 15:31:07,478: training iter 181, loss=0.07334119081497192 (11.952346s)
INFO:niftynet:2019-06-06 15:31:17,932: training iter 182, loss=0.06625667959451675 (10.453396s)
INFO:niftynet:2019-06-06 15:31:30,527: training iter 183, loss=0.06332125514745712 (12.594542s)
INFO:niftynet:2019-06-06 15:31:41,803: training iter 184, loss=0.06730788201093674 (11.275367s)
INFO:niftynet:2019-06-06 15:31:51,367: training iter 185, loss=0.06273248791694641 (9.563292s)
INFO:niftynet:2019-06-06 15:32:02,012: training iter 186, loss=0.06174521520733833 (10.645152s)
INFO:niftynet:2019-06-06 15:32:16,621: training iter 187, loss=0.07208987325429916 (14.608390s)
INFO:niftynet:2019-06-06 15:32:26,979: training iter 188, loss=0.06855348497629166 (10.357003s)
INFO:niftynet:2019-06-06 15:32:36,922: training iter 189, loss=0.0705728605389595 (9.939333s)
INFO:niftynet:2019-06-06 15:32:50,103: training iter 190, loss=0.06400901824235916 (13.180101s)
INFO:niftynet:2019-06-06 15:33:03,823: training iter 191, loss=0.07413213700056076 (13.709608s)
INFO:niftynet:2019-06-06 15:33:13,548: training iter 192, loss=0.07105764001607895 (9.724935s)
INFO:niftynet:2019-06-06 15:33:23,861: training iter 193, loss=0.111596018075943 (10.312384s)
INFO:niftynet:2019-06-06 15:33:37,208: training iter 194, loss=0.06974852085113525 (13.346703s)
INFO:niftynet:2019-06-06 15:33:49,905: training iter 195, loss=0.06733599305152893 (12.694911s)
INFO:niftynet:2019-06-06 15:33:57,753: training iter 196, loss=0.06965509802103043 (7.847762s)
INFO:niftynet:2019-06-06 15:34:07,896: training iter 197, loss=0.06381364911794662 (10.142500s)
INFO:niftynet:2019-06-06 15:34:22,947: training iter 198, loss=0.0703786090016365 (15.050620s)
INFO:niftynet:2019-06-06 15:34:38,226: training iter 199, loss=0.07007559388875961 (15.278897s)
INFO:niftynet:2019-06-06 15:34:47,578: training iter 200, loss=0.06491748243570328 (9.351696s)
INFO:niftynet:2019-06-06 15:34:49,903: iter 200 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:35:00,457: training iter 201, loss=0.06900495290756226 (10.530392s)
INFO:niftynet:2019-06-06 15:35:14,945: training iter 202, loss=0.06618551164865494 (14.486959s)
INFO:niftynet:2019-06-06 15:35:26,438: training iter 203, loss=0.0595240481197834 (11.492706s)
INFO:niftynet:2019-06-06 15:35:35,598: training iter 204, loss=0.06745108217000961 (9.159902s)
INFO:niftynet:2019-06-06 15:35:46,530: training iter 205, loss=0.06368932127952576 (10.931818s)
INFO:niftynet:2019-06-06 15:35:59,279: training iter 206, loss=0.0662490651011467 (12.748206s)
INFO:niftynet:2019-06-06 15:36:12,806: training iter 207, loss=0.06593737006187439 (13.526550s)
INFO:niftynet:2019-06-06 15:36:22,475: training iter 208, loss=0.06191403791308403 (9.668840s)
INFO:niftynet:2019-06-06 15:36:33,085: training iter 209, loss=0.07162723690271378 (10.608943s)
INFO:niftynet:2019-06-06 15:36:45,240: training iter 210, loss=0.05948339030146599 (12.155385s)
INFO:niftynet:2019-06-06 15:36:56,646: training iter 211, loss=0.06972729414701462 (11.347292s)
INFO:niftynet:2019-06-06 15:37:06,311: training iter 212, loss=0.08084174245595932 (9.664099s)
INFO:niftynet:2019-06-06 15:37:19,807: training iter 213, loss=0.06870540976524353 (13.495180s)
INFO:niftynet:2019-06-06 15:37:33,955: training iter 214, loss=0.06515222042798996 (14.148205s)
INFO:niftynet:2019-06-06 15:37:42,812: training iter 215, loss=0.06262218952178955 (8.855966s)
INFO:niftynet:2019-06-06 15:37:52,903: training iter 216, loss=0.06600917130708694 (10.091183s)
INFO:niftynet:2019-06-06 15:38:06,767: training iter 217, loss=0.06193262338638306 (13.863312s)
INFO:niftynet:2019-06-06 15:38:21,264: training iter 218, loss=0.06675329804420471 (14.496493s)
INFO:niftynet:2019-06-06 15:38:30,419: training iter 219, loss=0.06014619395136833 (9.154270s)
INFO:niftynet:2019-06-06 15:38:40,480: training iter 220, loss=0.06491192430257797 (10.059689s)
INFO:niftynet:2019-06-06 15:38:55,763: training iter 221, loss=0.06647437810897827 (15.270995s)
INFO:niftynet:2019-06-06 15:39:07,131: training iter 222, loss=0.06582179665565491 (11.367787s)
INFO:niftynet:2019-06-06 15:39:17,041: training iter 223, loss=0.0638333261013031 (9.909107s)
INFO:niftynet:2019-06-06 15:39:29,870: training iter 224, loss=0.06167656183242798 (12.828827s)
INFO:niftynet:2019-06-06 15:39:43,376: training iter 225, loss=0.06505361199378967 (13.505228s)
INFO:niftynet:2019-06-06 15:39:45,774: iter 225 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:39:55,040: training iter 226, loss=0.06538236886262894 (9.265171s)
INFO:niftynet:2019-06-06 15:40:05,521: training iter 227, loss=0.06897588819265366 (10.470837s)
INFO:niftynet:2019-06-06 15:40:15,395: training iter 228, loss=0.06179888918995857 (9.873714s)
INFO:niftynet:2019-06-06 15:40:27,423: training iter 229, loss=0.08543801307678223 (12.027332s)
INFO:niftynet:2019-06-06 15:40:37,641: training iter 230, loss=0.06641364097595215 (10.217370s)
INFO:niftynet:2019-06-06 15:40:49,295: training iter 231, loss=0.07395405322313309 (11.636362s)
INFO:niftynet:2019-06-06 15:41:01,630: training iter 232, loss=0.06312800198793411 (12.334588s)
INFO:niftynet:2019-06-06 15:41:13,895: training iter 233, loss=0.06536996364593506 (12.265003s)
INFO:niftynet:2019-06-06 15:41:23,977: training iter 234, loss=0.059872567653656006 (10.081209s)
INFO:niftynet:2019-06-06 15:41:36,043: training iter 235, loss=0.07228625565767288 (12.065846s)
INFO:niftynet:2019-06-06 15:41:49,230: training iter 236, loss=0.06744914501905441 (13.186512s)
INFO:niftynet:2019-06-06 15:41:59,699: training iter 237, loss=0.07028260827064514 (10.468295s)
INFO:niftynet:2019-06-06 15:42:10,114: training iter 238, loss=0.08253387361764908 (10.414924s)
INFO:niftynet:2019-06-06 15:42:22,995: training iter 239, loss=0.0608273446559906 (12.880297s)
INFO:niftynet:2019-06-06 15:42:35,528: training iter 240, loss=0.06748920679092407 (12.532801s)
INFO:niftynet:2019-06-06 15:42:45,229: training iter 241, loss=0.07388893514871597 (9.686434s)
INFO:niftynet:2019-06-06 15:42:55,582: training iter 242, loss=0.07769296318292618 (10.352464s)
INFO:niftynet:2019-06-06 15:43:09,943: training iter 243, loss=0.06713031977415085 (14.360262s)
INFO:niftynet:2019-06-06 15:43:22,524: training iter 244, loss=0.06003260612487793 (12.580867s)
INFO:niftynet:2019-06-06 15:43:32,507: training iter 245, loss=0.06480861455202103 (9.981987s)
INFO:niftynet:2019-06-06 15:43:43,042: training iter 246, loss=0.0655611976981163 (10.535158s)
INFO:niftynet:2019-06-06 15:43:57,464: training iter 247, loss=0.07604653388261795 (14.421057s)
INFO:niftynet:2019-06-06 15:44:08,691: training iter 248, loss=0.09108146280050278 (11.222956s)
INFO:niftynet:2019-06-06 15:44:18,686: training iter 249, loss=0.06356557458639145 (9.994949s)
INFO:niftynet:2019-06-06 15:44:30,512: training iter 250, loss=0.06098175048828125 (11.825284s)
INFO:niftynet:2019-06-06 15:44:32,736: iter 250 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:44:46,200: training iter 251, loss=0.07838651537895203 (13.455707s)
INFO:niftynet:2019-06-06 15:44:55,532: training iter 252, loss=0.061576832085847855 (9.331253s)
INFO:niftynet:2019-06-06 15:45:05,552: training iter 253, loss=0.06291821599006653 (10.019215s)
INFO:niftynet:2019-06-06 15:45:19,444: training iter 254, loss=0.062156517058610916 (13.892131s)
INFO:niftynet:2019-06-06 15:45:32,738: training iter 255, loss=0.06463871151208878 (13.293280s)
INFO:niftynet:2019-06-06 15:45:42,664: training iter 256, loss=0.06346416473388672 (9.925536s)
INFO:niftynet:2019-06-06 15:45:52,900: training iter 257, loss=0.06138418987393379 (10.230088s)
INFO:niftynet:2019-06-06 15:46:04,580: training iter 258, loss=0.06533508747816086 (11.678818s)
INFO:niftynet:2019-06-06 15:46:16,547: training iter 259, loss=0.06457075476646423 (11.967250s)
INFO:niftynet:2019-06-06 15:46:26,366: training iter 260, loss=0.06337029486894608 (9.808816s)
INFO:niftynet:2019-06-06 15:46:38,541: training iter 261, loss=0.0633479654788971 (12.164605s)
INFO:niftynet:2019-06-06 15:46:53,104: training iter 262, loss=0.06518193334341049 (14.562799s)
INFO:niftynet:2019-06-06 15:47:02,519: training iter 263, loss=0.08355864137411118 (9.414816s)
INFO:niftynet:2019-06-06 15:47:09,988: training iter 264, loss=0.06406658887863159 (7.468677s)
INFO:niftynet:2019-06-06 15:47:32,119: training iter 265, loss=0.07415030151605606 (22.130154s)
INFO:niftynet:2019-06-06 15:47:41,287: training iter 266, loss=0.06452048569917679 (9.168325s)
INFO:niftynet:2019-06-06 15:47:52,139: training iter 267, loss=0.07021487504243851 (10.851501s)
INFO:niftynet:2019-06-06 15:48:04,338: training iter 268, loss=0.07847238332033157 (12.198228s)
INFO:niftynet:2019-06-06 15:48:13,744: training iter 269, loss=0.06742548942565918 (9.405642s)
INFO:niftynet:2019-06-06 15:48:24,957: training iter 270, loss=0.07483672350645065 (11.212842s)
INFO:niftynet:2019-06-06 15:48:41,528: training iter 271, loss=0.07162091135978699 (16.545010s)
INFO:niftynet:2019-06-06 15:48:50,861: training iter 272, loss=0.0621316023170948 (9.332186s)
INFO:niftynet:2019-06-06 15:49:01,391: training iter 273, loss=0.06261200457811356 (10.530431s)
INFO:niftynet:2019-06-06 15:49:16,328: training iter 274, loss=0.05837075039744377 (14.935957s)
INFO:niftynet:2019-06-06 15:49:25,700: training iter 275, loss=0.06444099545478821 (9.371681s)
INFO:niftynet:2019-06-06 15:49:27,637: iter 275 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:49:37,770: training iter 276, loss=0.06626506894826889 (10.130330s)
INFO:niftynet:2019-06-06 15:49:48,155: training iter 277, loss=0.062265586107969284 (10.384962s)
INFO:niftynet:2019-06-06 15:50:02,332: training iter 278, loss=0.06328777223825455 (14.176125s)
INFO:niftynet:2019-06-06 15:50:12,307: training iter 279, loss=0.06749710440635681 (9.974691s)
INFO:niftynet:2019-06-06 15:50:24,158: training iter 280, loss=0.06978859752416611 (11.850750s)
INFO:niftynet:2019-06-06 15:50:36,783: training iter 281, loss=0.07891453057527542 (12.616446s)
INFO:niftynet:2019-06-06 15:50:46,632: training iter 282, loss=0.06682711839675903 (9.848317s)
INFO:niftynet:2019-06-06 15:50:56,678: training iter 283, loss=0.0608445405960083 (10.042568s)
INFO:niftynet:2019-06-06 15:51:10,460: training iter 284, loss=0.062463004142045975 (13.782087s)
INFO:niftynet:2019-06-06 15:51:22,799: training iter 285, loss=0.06774751096963882 (12.338177s)
INFO:niftynet:2019-06-06 15:51:32,377: training iter 286, loss=0.06329930573701859 (9.578069s)
INFO:niftynet:2019-06-06 15:51:43,491: training iter 287, loss=0.06644152849912643 (11.113250s)
INFO:niftynet:2019-06-06 15:51:57,307: training iter 288, loss=0.09031947702169418 (13.800143s)
INFO:niftynet:2019-06-06 15:52:07,966: training iter 289, loss=0.07295534014701843 (10.658147s)
INFO:niftynet:2019-06-06 15:52:18,373: training iter 290, loss=0.07315834611654282 (10.390172s)
INFO:niftynet:2019-06-06 15:52:30,191: training iter 291, loss=0.060161929577589035 (11.806762s)
INFO:niftynet:2019-06-06 15:52:42,275: training iter 292, loss=0.06592047959566116 (12.083991s)
INFO:niftynet:2019-06-06 15:52:52,095: training iter 293, loss=0.06117025017738342 (9.819149s)
INFO:niftynet:2019-06-06 15:53:04,082: training iter 294, loss=0.07273753732442856 (11.986686s)
INFO:niftynet:2019-06-06 15:53:19,147: training iter 295, loss=0.0583530068397522 (15.065121s)
INFO:niftynet:2019-06-06 15:53:29,492: training iter 296, loss=0.06794139742851257 (10.343607s)
INFO:niftynet:2019-06-06 15:53:39,524: training iter 297, loss=0.07907591015100479 (10.031318s)
INFO:niftynet:2019-06-06 15:53:51,583: training iter 298, loss=0.06011642888188362 (12.059306s)
INFO:niftynet:2019-06-06 15:54:07,931: training iter 299, loss=0.07520225644111633 (16.347642s)
INFO:niftynet:2019-06-06 15:54:17,165: training iter 300, loss=0.06360258907079697 (9.233174s)
INFO:niftynet:2019-06-06 15:54:19,731: iter 300 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:54:29,233: training iter 301, loss=0.0757572278380394 (9.491751s)
INFO:niftynet:2019-06-06 15:54:43,161: training iter 302, loss=0.06800264120101929 (13.927495s)
INFO:niftynet:2019-06-06 15:54:52,461: training iter 303, loss=0.06316127628087997 (9.299359s)
INFO:niftynet:2019-06-06 15:55:02,504: training iter 304, loss=0.06728255748748779 (10.042184s)
INFO:niftynet:2019-06-06 15:55:17,201: training iter 305, loss=0.0784468948841095 (14.697038s)
INFO:niftynet:2019-06-06 15:55:31,436: training iter 306, loss=0.06636449694633484 (14.234496s)
INFO:niftynet:2019-06-06 15:55:40,666: training iter 307, loss=0.06113281846046448 (9.229684s)
INFO:niftynet:2019-06-06 15:55:50,922: training iter 308, loss=0.06527426093816757 (10.255205s)
INFO:niftynet:2019-06-06 15:56:05,222: training iter 309, loss=0.062114179134368896 (14.300373s)
INFO:niftynet:2019-06-06 15:56:14,414: training iter 310, loss=0.06246715784072876 (9.191476s)
INFO:niftynet:2019-06-06 15:56:24,234: training iter 311, loss=0.07100560516119003 (9.808768s)
INFO:niftynet:2019-06-06 15:56:38,763: training iter 312, loss=0.06350573897361755 (14.528296s)
INFO:niftynet:2019-06-06 15:56:49,047: training iter 313, loss=0.07395538687705994 (10.282902s)
INFO:niftynet:2019-06-06 15:57:00,671: training iter 314, loss=0.07494231313467026 (11.624090s)
INFO:niftynet:2019-06-06 15:57:10,915: training iter 315, loss=0.06022869423031807 (10.243201s)
INFO:niftynet:2019-06-06 15:57:21,708: training iter 316, loss=0.0696936547756195 (10.792377s)
INFO:niftynet:2019-06-06 15:57:33,921: training iter 317, loss=0.06885235756635666 (12.212823s)
INFO:niftynet:2019-06-06 15:57:47,878: training iter 318, loss=0.06193099543452263 (13.956330s)
INFO:niftynet:2019-06-06 15:57:57,323: training iter 319, loss=0.06903690844774246 (9.445340s)
INFO:niftynet:2019-06-06 15:58:07,515: training iter 320, loss=0.07346868515014648 (10.191428s)
INFO:niftynet:2019-06-06 15:58:22,320: training iter 321, loss=0.06325185298919678 (14.795585s)
INFO:niftynet:2019-06-06 15:58:31,861: training iter 322, loss=0.057681214064359665 (9.540698s)
INFO:niftynet:2019-06-06 15:58:41,934: training iter 323, loss=0.06139213964343071 (10.067247s)
INFO:niftynet:2019-06-06 15:58:57,475: training iter 324, loss=0.0808224081993103 (15.539945s)
INFO:niftynet:2019-06-06 15:59:12,050: training iter 325, loss=0.06537779420614243 (14.574589s)
INFO:niftynet:2019-06-06 15:59:13,927: iter 325 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 15:59:22,937: training iter 326, loss=0.07066988945007324 (9.009807s)
INFO:niftynet:2019-06-06 15:59:33,134: training iter 327, loss=0.06382635980844498 (10.184944s)
INFO:niftynet:2019-06-06 15:59:44,669: training iter 328, loss=0.07538178563117981 (11.534739s)
INFO:niftynet:2019-06-06 15:59:58,038: training iter 329, loss=0.10900083184242249 (13.368770s)
INFO:niftynet:2019-06-06 16:00:07,577: training iter 330, loss=0.07115186005830765 (9.538291s)
INFO:niftynet:2019-06-06 16:00:18,108: training iter 331, loss=0.06867439299821854 (10.506964s)
INFO:niftynet:2019-06-06 16:00:27,806: training iter 332, loss=0.09160396456718445 (9.697771s)
INFO:niftynet:2019-06-06 16:00:46,502: training iter 333, loss=0.06769771128892899 (18.694585s)
INFO:niftynet:2019-06-06 16:00:59,368: training iter 334, loss=0.07094689458608627 (12.865522s)
INFO:niftynet:2019-06-06 16:01:08,845: training iter 335, loss=0.09092143177986145 (9.477071s)
INFO:niftynet:2019-06-06 16:01:20,805: training iter 336, loss=0.06452688574790955 (11.948017s)
INFO:niftynet:2019-06-06 16:01:31,499: training iter 337, loss=0.12169406563043594 (10.694256s)
INFO:niftynet:2019-06-06 16:01:43,852: training iter 338, loss=0.09053651243448257 (12.352389s)
INFO:niftynet:2019-06-06 16:01:53,698: training iter 339, loss=0.1142752468585968 (9.842754s)
INFO:niftynet:2019-06-06 16:02:07,291: training iter 340, loss=0.08459735661745071 (13.592809s)
INFO:niftynet:2019-06-06 16:02:17,166: training iter 341, loss=0.0762137845158577 (9.859991s)
INFO:niftynet:2019-06-06 16:02:30,431: training iter 342, loss=0.07890532165765762 (13.264531s)
INFO:niftynet:2019-06-06 16:02:40,457: training iter 343, loss=0.08174999803304672 (10.025170s)
INFO:niftynet:2019-06-06 16:02:54,382: training iter 344, loss=0.0731213167309761 (13.918968s)
INFO:niftynet:2019-06-06 16:03:03,804: training iter 345, loss=0.0772411897778511 (9.421923s)
INFO:niftynet:2019-06-06 16:03:16,956: training iter 346, loss=0.07805851846933365 (13.150652s)
INFO:niftynet:2019-06-06 16:03:27,673: training iter 347, loss=0.06897567957639694 (10.716787s)
INFO:niftynet:2019-06-06 16:03:39,702: training iter 348, loss=0.07766059786081314 (12.029048s)
INFO:niftynet:2019-06-06 16:03:49,520: training iter 349, loss=0.07725455611944199 (9.817734s)
INFO:niftynet:2019-06-06 16:04:01,786: training iter 350, loss=0.11493655294179916 (12.263578s)
INFO:niftynet:2019-06-06 16:04:03,945: iter 350 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:04:14,538: training iter 351, loss=0.06890692561864853 (10.584219s)
INFO:niftynet:2019-06-06 16:04:29,031: training iter 352, loss=0.07792829722166061 (14.493110s)
INFO:niftynet:2019-06-06 16:04:38,781: training iter 353, loss=0.09709737449884415 (9.749048s)
INFO:niftynet:2019-06-06 16:04:49,225: training iter 354, loss=0.08352595567703247 (10.440946s)
INFO:niftynet:2019-06-06 16:05:01,274: training iter 355, loss=0.07324273139238358 (12.048007s)
INFO:niftynet:2019-06-06 16:05:15,548: training iter 356, loss=0.0700928270816803 (14.273978s)
INFO:niftynet:2019-06-06 16:05:24,898: training iter 357, loss=0.06928234547376633 (9.349880s)
INFO:niftynet:2019-06-06 16:05:35,392: training iter 358, loss=0.07449555397033691 (10.493086s)
INFO:niftynet:2019-06-06 16:05:50,445: training iter 359, loss=0.07464244961738586 (15.052766s)
INFO:niftynet:2019-06-06 16:06:01,105: training iter 360, loss=0.08197123557329178 (10.659364s)
INFO:niftynet:2019-06-06 16:06:11,027: training iter 361, loss=0.06521496921777725 (9.875741s)
INFO:niftynet:2019-06-06 16:06:22,700: training iter 362, loss=0.06773096323013306 (11.672184s)
INFO:niftynet:2019-06-06 16:06:35,913: training iter 363, loss=0.06617946177721024 (13.212833s)
INFO:niftynet:2019-06-06 16:06:47,738: training iter 364, loss=0.0783848837018013 (11.824948s)
INFO:niftynet:2019-06-06 16:06:57,626: training iter 365, loss=0.08035007864236832 (9.887313s)
INFO:niftynet:2019-06-06 16:07:09,983: training iter 366, loss=0.07925606518983841 (12.357092s)
INFO:niftynet:2019-06-06 16:07:21,551: training iter 367, loss=0.07687059789896011 (11.567474s)
INFO:niftynet:2019-06-06 16:07:31,579: training iter 368, loss=0.06914988905191422 (10.027399s)
INFO:niftynet:2019-06-06 16:07:41,863: training iter 369, loss=0.07268578559160233 (10.284029s)
INFO:niftynet:2019-06-06 16:07:57,106: training iter 370, loss=0.07919931411743164 (15.223419s)
INFO:niftynet:2019-06-06 16:08:06,591: training iter 371, loss=0.07863396406173706 (9.454632s)
INFO:niftynet:2019-06-06 16:08:16,312: training iter 372, loss=0.07675869017839432 (9.719951s)
INFO:niftynet:2019-06-06 16:08:32,545: training iter 373, loss=0.07204339653253555 (16.232647s)
INFO:niftynet:2019-06-06 16:08:43,279: training iter 374, loss=0.06696874648332596 (10.734189s)
INFO:niftynet:2019-06-06 16:08:53,389: training iter 375, loss=0.0674087330698967 (10.109265s)
INFO:niftynet:2019-06-06 16:08:55,492: iter 375 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:09:05,232: training iter 376, loss=0.07543301582336426 (9.733851s)
INFO:niftynet:2019-06-06 16:09:19,676: training iter 377, loss=0.08535604923963547 (14.443757s)
INFO:niftynet:2019-06-06 16:09:28,597: training iter 378, loss=0.06206272169947624 (8.919954s)
INFO:niftynet:2019-06-06 16:09:38,326: training iter 379, loss=0.06816708296537399 (9.728762s)
INFO:niftynet:2019-06-06 16:09:52,215: training iter 380, loss=0.08179754763841629 (13.889103s)
INFO:niftynet:2019-06-06 16:10:06,499: training iter 381, loss=0.06869713217020035 (14.232154s)
INFO:niftynet:2019-06-06 16:10:16,007: training iter 382, loss=0.06788163632154465 (9.507705s)
INFO:niftynet:2019-06-06 16:10:26,876: training iter 383, loss=0.0701201856136322 (10.864131s)
INFO:niftynet:2019-06-06 16:10:40,339: training iter 384, loss=0.06811609864234924 (13.462500s)
INFO:niftynet:2019-06-06 16:10:50,872: training iter 385, loss=0.05868654325604439 (10.533028s)
INFO:niftynet:2019-06-06 16:11:00,954: training iter 386, loss=0.068184494972229 (10.081645s)
INFO:niftynet:2019-06-06 16:11:13,842: training iter 387, loss=0.06615317612886429 (12.888036s)
INFO:niftynet:2019-06-06 16:11:27,483: training iter 388, loss=0.0668352022767067 (13.640448s)
INFO:niftynet:2019-06-06 16:11:37,051: training iter 389, loss=0.06343931704759598 (9.567553s)
INFO:niftynet:2019-06-06 16:11:47,491: training iter 390, loss=0.07685652375221252 (10.438883s)
INFO:niftynet:2019-06-06 16:12:02,845: training iter 391, loss=0.09233007580041885 (15.346012s)
INFO:niftynet:2019-06-06 16:12:14,143: training iter 392, loss=0.060735154896974564 (11.297770s)
INFO:niftynet:2019-06-06 16:12:23,933: training iter 393, loss=0.06484229117631912 (9.789097s)
INFO:niftynet:2019-06-06 16:12:33,719: training iter 394, loss=0.07798898220062256 (9.785741s)
INFO:niftynet:2019-06-06 16:12:49,771: training iter 395, loss=0.07540366798639297 (16.051885s)
INFO:niftynet:2019-06-06 16:12:58,628: training iter 396, loss=0.06340711563825607 (8.855707s)
INFO:niftynet:2019-06-06 16:13:08,843: training iter 397, loss=0.0705999955534935 (10.215063s)
INFO:niftynet:2019-06-06 16:13:22,802: training iter 398, loss=0.06593307852745056 (13.955152s)
INFO:niftynet:2019-06-06 16:13:33,411: training iter 399, loss=0.06943165510892868 (10.608351s)
INFO:niftynet:2019-06-06 16:13:41,020: training iter 400, loss=0.07161431759595871 (7.609233s)
INFO:niftynet:2019-06-06 16:13:44,172: iter 400 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:14:01,493: training iter 401, loss=0.06686622649431229 (17.256256s)
INFO:niftynet:2019-06-06 16:14:15,777: training iter 402, loss=0.08155132085084915 (14.283853s)
INFO:niftynet:2019-06-06 16:14:25,087: training iter 403, loss=0.06370734423398972 (9.309702s)
INFO:niftynet:2019-06-06 16:14:34,887: training iter 404, loss=0.08451540023088455 (9.799849s)
INFO:niftynet:2019-06-06 16:14:50,183: training iter 405, loss=0.07792773097753525 (15.295677s)
INFO:niftynet:2019-06-06 16:15:00,810: training iter 406, loss=0.07296493649482727 (10.626708s)
INFO:niftynet:2019-06-06 16:15:10,936: training iter 407, loss=0.1061302050948143 (10.123521s)
INFO:niftynet:2019-06-06 16:15:22,495: training iter 408, loss=0.08828004449605942 (11.558418s)
INFO:niftynet:2019-06-06 16:15:35,763: training iter 409, loss=0.07455307245254517 (13.266978s)
INFO:niftynet:2019-06-06 16:15:45,259: training iter 410, loss=0.07269161194562912 (9.495729s)
INFO:niftynet:2019-06-06 16:15:55,027: training iter 411, loss=0.08727923035621643 (9.719068s)
INFO:niftynet:2019-06-06 16:16:09,447: training iter 412, loss=0.0850554034113884 (14.414907s)
INFO:niftynet:2019-06-06 16:16:23,189: training iter 413, loss=0.07529447227716446 (13.741752s)
INFO:niftynet:2019-06-06 16:16:33,048: training iter 414, loss=0.07081273943185806 (9.858250s)
INFO:niftynet:2019-06-06 16:16:44,271: training iter 415, loss=0.0694199874997139 (11.223097s)
INFO:niftynet:2019-06-06 16:16:56,233: training iter 416, loss=0.06902725249528885 (11.961124s)
INFO:niftynet:2019-06-06 16:17:08,751: training iter 417, loss=0.08191881328821182 (12.517950s)
INFO:niftynet:2019-06-06 16:17:18,573: training iter 418, loss=0.06894450634717941 (9.821156s)
INFO:niftynet:2019-06-06 16:17:28,594: training iter 419, loss=0.07366809993982315 (10.020736s)
INFO:niftynet:2019-06-06 16:17:44,310: training iter 420, loss=0.06464622169733047 (15.715990s)
INFO:niftynet:2019-06-06 16:17:53,844: training iter 421, loss=0.06757977604866028 (9.518355s)
INFO:niftynet:2019-06-06 16:18:04,027: training iter 422, loss=0.08205046504735947 (10.182765s)
INFO:niftynet:2019-06-06 16:18:20,078: training iter 423, loss=0.06670305877923965 (16.050913s)
INFO:niftynet:2019-06-06 16:18:30,593: training iter 424, loss=0.06789889931678772 (10.512807s)
INFO:niftynet:2019-06-06 16:18:40,454: training iter 425, loss=0.06643977761268616 (9.855128s)
INFO:niftynet:2019-06-06 16:18:42,586: iter 425 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:18:52,378: training iter 426, loss=0.06284374743700027 (9.791463s)
INFO:niftynet:2019-06-06 16:19:06,209: training iter 427, loss=0.06739416718482971 (13.830348s)
INFO:niftynet:2019-06-06 16:19:15,975: training iter 428, loss=0.0644862949848175 (9.766033s)
INFO:niftynet:2019-06-06 16:19:25,962: training iter 429, loss=0.0679318979382515 (9.985861s)
INFO:niftynet:2019-06-06 16:19:41,432: training iter 430, loss=0.0634305402636528 (15.470342s)
INFO:niftynet:2019-06-06 16:19:53,003: training iter 431, loss=0.05976198986172676 (11.562068s)
INFO:niftynet:2019-06-06 16:20:02,727: training iter 432, loss=0.07043047994375229 (9.723114s)
INFO:niftynet:2019-06-06 16:20:13,992: training iter 433, loss=0.06289667636156082 (11.265029s)
INFO:niftynet:2019-06-06 16:20:26,912: training iter 434, loss=0.064893938601017 (12.919394s)
INFO:niftynet:2019-06-06 16:20:42,597: training iter 435, loss=0.06402269750833511 (15.684234s)
INFO:niftynet:2019-06-06 16:20:51,821: training iter 436, loss=0.07803625613451004 (9.223478s)
INFO:niftynet:2019-06-06 16:21:02,409: training iter 437, loss=0.0704270601272583 (10.588346s)
INFO:niftynet:2019-06-06 16:21:13,673: training iter 438, loss=0.07396966964006424 (11.262856s)
INFO:niftynet:2019-06-06 16:21:24,029: training iter 439, loss=0.06285452842712402 (10.355907s)
INFO:niftynet:2019-06-06 16:21:33,785: training iter 440, loss=0.06473582983016968 (9.754426s)
INFO:niftynet:2019-06-06 16:21:48,427: training iter 441, loss=0.06532708555459976 (14.634561s)
INFO:niftynet:2019-06-06 16:21:57,965: training iter 442, loss=0.06924637407064438 (9.536769s)
INFO:niftynet:2019-06-06 16:22:09,789: training iter 443, loss=0.09654947370290756 (11.823435s)
INFO:niftynet:2019-06-06 16:22:22,035: training iter 444, loss=0.059508442878723145 (12.246417s)
INFO:niftynet:2019-06-06 16:22:32,815: training iter 445, loss=0.06844352930784225 (10.779180s)
INFO:niftynet:2019-06-06 16:22:43,495: training iter 446, loss=0.07478269189596176 (10.668625s)
INFO:niftynet:2019-06-06 16:22:55,722: training iter 447, loss=0.06475291401147842 (12.226643s)
INFO:niftynet:2019-06-06 16:23:11,002: training iter 448, loss=0.06298759579658508 (15.279227s)
INFO:niftynet:2019-06-06 16:23:20,145: training iter 449, loss=0.07494030147790909 (9.143341s)
INFO:niftynet:2019-06-06 16:23:30,866: training iter 450, loss=0.07719632238149643 (10.719963s)
INFO:niftynet:2019-06-06 16:23:33,018: iter 450 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:23:44,179: training iter 451, loss=0.07037057727575302 (11.141196s)
INFO:niftynet:2019-06-06 16:23:59,874: training iter 452, loss=0.062001604586839676 (15.693829s)
INFO:niftynet:2019-06-06 16:24:09,258: training iter 453, loss=0.05756537988781929 (9.383723s)
INFO:niftynet:2019-06-06 16:24:18,875: training iter 454, loss=0.06031723693013191 (9.607725s)
INFO:niftynet:2019-06-06 16:24:31,531: training iter 455, loss=0.057372529059648514 (12.655611s)
INFO:niftynet:2019-06-06 16:24:44,015: training iter 456, loss=0.05837888643145561 (12.477962s)
INFO:niftynet:2019-06-06 16:24:53,750: training iter 457, loss=0.07596176117658615 (9.734207s)
INFO:niftynet:2019-06-06 16:25:05,507: training iter 458, loss=0.06489270180463791 (11.757299s)
INFO:niftynet:2019-06-06 16:25:19,308: training iter 459, loss=0.0674702450633049 (13.800402s)
INFO:niftynet:2019-06-06 16:25:31,501: training iter 460, loss=0.06521031260490417 (12.192630s)
INFO:niftynet:2019-06-06 16:25:41,083: training iter 461, loss=0.064240962266922 (9.566912s)
INFO:niftynet:2019-06-06 16:25:53,832: training iter 462, loss=0.0708509087562561 (12.748338s)
INFO:niftynet:2019-06-06 16:26:05,812: training iter 463, loss=0.07561296224594116 (11.980066s)
INFO:niftynet:2019-06-06 16:26:16,910: training iter 464, loss=0.05211642384529114 (11.097059s)
INFO:niftynet:2019-06-06 16:26:26,605: training iter 465, loss=0.061826396733522415 (9.694702s)
INFO:niftynet:2019-06-06 16:26:38,290: training iter 466, loss=0.062410902231931686 (11.684371s)
INFO:niftynet:2019-06-06 16:26:49,098: training iter 467, loss=0.06550801545381546 (10.807575s)
INFO:niftynet:2019-06-06 16:27:09,229: training iter 468, loss=0.06834873557090759 (20.130561s)
INFO:niftynet:2019-06-06 16:27:18,651: training iter 469, loss=0.06879640370607376 (9.410474s)
INFO:niftynet:2019-06-06 16:27:28,373: training iter 470, loss=0.060761988162994385 (9.721715s)
INFO:niftynet:2019-06-06 16:27:44,507: training iter 471, loss=0.06796493381261826 (16.121063s)
INFO:niftynet:2019-06-06 16:27:53,813: training iter 472, loss=0.08534568548202515 (9.305852s)
INFO:niftynet:2019-06-06 16:28:04,300: training iter 473, loss=0.10631493479013443 (10.487017s)
INFO:niftynet:2019-06-06 16:28:17,277: training iter 474, loss=0.05921526625752449 (12.976538s)
INFO:niftynet:2019-06-06 16:28:26,430: training iter 475, loss=0.07511455565690994 (9.152195s)
INFO:niftynet:2019-06-06 16:28:28,472: iter 475 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:28:38,386: training iter 476, loss=0.0626344308257103 (9.913039s)
INFO:niftynet:2019-06-06 16:28:51,380: training iter 477, loss=0.07593036442995071 (12.993032s)
INFO:niftynet:2019-06-06 16:29:01,869: training iter 478, loss=0.06557173281908035 (10.489227s)
INFO:niftynet:2019-06-06 16:29:11,989: training iter 479, loss=0.06405702233314514 (10.117538s)
INFO:niftynet:2019-06-06 16:29:24,960: training iter 480, loss=0.06437930464744568 (12.970420s)
INFO:niftynet:2019-06-06 16:29:38,272: training iter 481, loss=0.06396538764238358 (13.276665s)
INFO:niftynet:2019-06-06 16:29:47,970: training iter 482, loss=0.05953385308384895 (9.697975s)
INFO:niftynet:2019-06-06 16:29:59,432: training iter 483, loss=0.07796340435743332 (11.460884s)
INFO:niftynet:2019-06-06 16:30:13,325: training iter 484, loss=0.05376358702778816 (13.892549s)
INFO:niftynet:2019-06-06 16:30:22,629: training iter 485, loss=0.06256210803985596 (9.196203s)
INFO:niftynet:2019-06-06 16:30:32,224: training iter 486, loss=0.06728386133909225 (9.594993s)
INFO:niftynet:2019-06-06 16:30:47,656: training iter 487, loss=0.07151328772306442 (15.430895s)
INFO:niftynet:2019-06-06 16:31:00,220: training iter 488, loss=0.06172902509570122 (12.563633s)
INFO:niftynet:2019-06-06 16:31:09,674: training iter 489, loss=0.06372949481010437 (9.453450s)
INFO:niftynet:2019-06-06 16:31:19,134: training iter 490, loss=0.07298418879508972 (9.460499s)
INFO:niftynet:2019-06-06 16:31:35,559: training iter 491, loss=0.05737600848078728 (16.416664s)
INFO:niftynet:2019-06-06 16:31:44,677: training iter 492, loss=0.0617605559527874 (9.117130s)
INFO:niftynet:2019-06-06 16:31:54,740: training iter 493, loss=0.0662667453289032 (10.063137s)
INFO:niftynet:2019-06-06 16:32:08,090: training iter 494, loss=0.0754845142364502 (13.347779s)
INFO:niftynet:2019-06-06 16:32:19,372: training iter 495, loss=0.06992759555578232 (11.282228s)
INFO:niftynet:2019-06-06 16:32:29,069: training iter 496, loss=0.06817241758108139 (9.696859s)
INFO:niftynet:2019-06-06 16:32:41,921: training iter 497, loss=0.05739005282521248 (12.851675s)
INFO:niftynet:2019-06-06 16:32:55,258: training iter 498, loss=0.06370335817337036 (13.334585s)
INFO:niftynet:2019-06-06 16:33:04,888: training iter 499, loss=0.061492402106523514 (9.629987s)
INFO:niftynet:2019-06-06 16:33:15,366: training iter 500, loss=0.07481729984283447 (10.477672s)
INFO:niftynet:2019-06-06 16:33:17,981: iter 500 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:33:30,640: training iter 501, loss=0.06129097938537598 (12.648790s)
INFO:niftynet:2019-06-06 16:33:40,433: training iter 502, loss=0.061559904366731644 (9.792458s)
INFO:niftynet:2019-06-06 16:33:50,271: training iter 503, loss=0.05998900532722473 (9.838262s)
INFO:niftynet:2019-06-06 16:34:04,605: training iter 504, loss=0.06270792335271835 (14.332950s)
INFO:niftynet:2019-06-06 16:34:14,663: training iter 505, loss=0.06685762852430344 (10.058214s)
INFO:niftynet:2019-06-06 16:34:24,440: training iter 506, loss=0.06428251415491104 (9.775901s)
INFO:niftynet:2019-06-06 16:34:37,131: training iter 507, loss=0.06526588648557663 (12.690738s)
INFO:niftynet:2019-06-06 16:34:48,828: training iter 508, loss=0.07228079438209534 (11.696348s)
INFO:niftynet:2019-06-06 16:34:58,904: training iter 509, loss=0.058642178773880005 (10.076231s)
INFO:niftynet:2019-06-06 16:35:10,617: training iter 510, loss=0.07100888341665268 (11.712579s)
INFO:niftynet:2019-06-06 16:35:25,746: training iter 511, loss=0.06441827863454819 (15.106090s)
INFO:niftynet:2019-06-06 16:35:35,324: training iter 512, loss=0.06692323088645935 (9.572953s)
INFO:niftynet:2019-06-06 16:35:45,222: training iter 513, loss=0.05906035378575325 (9.897221s)
INFO:niftynet:2019-06-06 16:35:57,351: training iter 514, loss=0.06023974344134331 (12.129131s)
INFO:niftynet:2019-06-06 16:36:11,157: training iter 515, loss=0.06217936798930168 (13.805623s)
INFO:niftynet:2019-06-06 16:36:20,516: training iter 516, loss=0.061537522822618484 (9.358876s)
INFO:niftynet:2019-06-06 16:36:30,184: training iter 517, loss=0.06552497297525406 (9.667687s)
INFO:niftynet:2019-06-06 16:36:44,757: training iter 518, loss=0.0560162179172039 (14.572377s)
INFO:niftynet:2019-06-06 16:36:55,975: training iter 519, loss=0.06296631693840027 (11.217644s)
INFO:niftynet:2019-06-06 16:37:06,031: training iter 520, loss=0.061799436807632446 (10.053241s)
INFO:niftynet:2019-06-06 16:37:18,840: training iter 521, loss=0.06353535503149033 (12.800685s)
INFO:niftynet:2019-06-06 16:37:30,509: training iter 522, loss=0.06112419441342354 (11.658429s)
INFO:niftynet:2019-06-06 16:37:42,134: training iter 523, loss=0.0751967653632164 (11.624773s)
INFO:niftynet:2019-06-06 16:37:51,844: training iter 524, loss=0.06135793402791023 (9.709219s)
INFO:niftynet:2019-06-06 16:38:03,934: training iter 525, loss=0.06453263759613037 (12.089437s)
INFO:niftynet:2019-06-06 16:38:05,958: iter 525 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:38:17,992: training iter 526, loss=0.0645926296710968 (12.033535s)
INFO:niftynet:2019-06-06 16:38:29,119: training iter 527, loss=0.06251149624586105 (11.127143s)
INFO:niftynet:2019-06-06 16:38:39,256: training iter 528, loss=0.06313744932413101 (10.136758s)
INFO:niftynet:2019-06-06 16:38:51,295: training iter 529, loss=0.06278873234987259 (12.037847s)
INFO:niftynet:2019-06-06 16:39:03,575: training iter 530, loss=0.06066763401031494 (12.280374s)
INFO:niftynet:2019-06-06 16:39:14,623: training iter 531, loss=0.06034187600016594 (11.020069s)
INFO:niftynet:2019-06-06 16:39:24,365: training iter 532, loss=0.06711145490407944 (9.741504s)
INFO:niftynet:2019-06-06 16:39:37,478: training iter 533, loss=0.05982964113354683 (13.112524s)
INFO:niftynet:2019-06-06 16:39:49,101: training iter 534, loss=0.058155130594968796 (11.620685s)
INFO:niftynet:2019-06-06 16:39:56,791: training iter 535, loss=0.06096115708351135 (7.689487s)
INFO:niftynet:2019-06-06 16:40:17,167: training iter 536, loss=0.06586211174726486 (20.375717s)
INFO:niftynet:2019-06-06 16:40:27,322: training iter 537, loss=0.06248176097869873 (10.152867s)
INFO:niftynet:2019-06-06 16:40:37,240: training iter 538, loss=0.06124963238835335 (9.916462s)
INFO:niftynet:2019-06-06 16:40:48,253: training iter 539, loss=0.06080588698387146 (11.012797s)
INFO:niftynet:2019-06-06 16:41:00,386: training iter 540, loss=0.0839795172214508 (12.132850s)
INFO:niftynet:2019-06-06 16:41:10,068: training iter 541, loss=0.06833469867706299 (9.673756s)
INFO:niftynet:2019-06-06 16:41:22,306: training iter 542, loss=0.06358977407217026 (12.237629s)
INFO:niftynet:2019-06-06 16:41:35,841: training iter 543, loss=0.05823464319109917 (13.535281s)
INFO:niftynet:2019-06-06 16:41:49,507: training iter 544, loss=0.062333036214113235 (13.664680s)
INFO:niftynet:2019-06-06 16:41:59,354: training iter 545, loss=0.06899434328079224 (9.847076s)
INFO:niftynet:2019-06-06 16:42:10,019: training iter 546, loss=0.06414014101028442 (10.664777s)
INFO:niftynet:2019-06-06 16:42:21,158: training iter 547, loss=0.05884256958961487 (11.138633s)
INFO:niftynet:2019-06-06 16:42:35,000: training iter 548, loss=0.06121889874339104 (13.841343s)
INFO:niftynet:2019-06-06 16:42:44,460: training iter 549, loss=0.05989290401339531 (9.444581s)
INFO:niftynet:2019-06-06 16:42:56,268: training iter 550, loss=0.06147119402885437 (11.807961s)
INFO:niftynet:2019-06-06 16:42:58,516: iter 550 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:43:07,945: training iter 551, loss=0.0764685869216919 (9.420396s)
INFO:niftynet:2019-06-06 16:43:18,843: training iter 552, loss=0.061799000948667526 (10.897765s)
INFO:niftynet:2019-06-06 16:43:29,575: training iter 553, loss=0.0603063702583313 (10.731688s)
INFO:niftynet:2019-06-06 16:43:44,981: training iter 554, loss=0.06362783163785934 (15.405847s)
INFO:niftynet:2019-06-06 16:43:54,049: training iter 555, loss=0.06146575137972832 (9.066411s)
INFO:niftynet:2019-06-06 16:44:03,874: training iter 556, loss=0.05585837364196777 (9.824477s)
INFO:niftynet:2019-06-06 16:44:16,417: training iter 557, loss=0.06363004446029663 (12.543477s)
INFO:niftynet:2019-06-06 16:44:30,183: training iter 558, loss=0.060305435210466385 (13.765129s)
INFO:niftynet:2019-06-06 16:44:39,423: training iter 559, loss=0.06367190927267075 (9.239293s)
INFO:niftynet:2019-06-06 16:44:48,859: training iter 560, loss=0.06797271966934204 (9.431297s)
INFO:niftynet:2019-06-06 16:45:04,160: training iter 561, loss=0.0623919777572155 (15.285174s)
INFO:niftynet:2019-06-06 16:45:15,962: training iter 562, loss=0.0629836842417717 (11.801487s)
INFO:niftynet:2019-06-06 16:45:26,060: training iter 563, loss=0.06300478428602219 (10.097598s)
INFO:niftynet:2019-06-06 16:45:37,825: training iter 564, loss=0.06718602031469345 (11.763919s)
INFO:niftynet:2019-06-06 16:45:49,963: training iter 565, loss=0.06658869981765747 (12.138188s)
INFO:niftynet:2019-06-06 16:46:03,323: training iter 566, loss=0.06207770109176636 (13.359675s)
INFO:niftynet:2019-06-06 16:46:13,013: training iter 567, loss=0.06006721779704094 (9.689662s)
INFO:niftynet:2019-06-06 16:46:23,120: training iter 568, loss=0.0703769326210022 (10.105950s)
INFO:niftynet:2019-06-06 16:46:36,580: training iter 569, loss=0.05841837450861931 (13.459968s)
INFO:niftynet:2019-06-06 16:46:47,493: training iter 570, loss=0.06331285089254379 (10.912322s)
INFO:niftynet:2019-06-06 16:46:57,621: training iter 571, loss=0.059135813266038895 (10.114972s)
INFO:niftynet:2019-06-06 16:47:11,491: training iter 572, loss=0.06669055670499802 (13.869908s)
INFO:niftynet:2019-06-06 16:47:22,067: training iter 573, loss=0.06747642159461975 (10.574920s)
INFO:niftynet:2019-06-06 16:47:32,390: training iter 574, loss=0.07450392842292786 (10.320170s)
INFO:niftynet:2019-06-06 16:47:43,649: training iter 575, loss=0.06384747475385666 (11.258645s)
INFO:niftynet:2019-06-06 16:47:45,958: iter 575 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:47:59,418: training iter 576, loss=0.07312210649251938 (13.459616s)
INFO:niftynet:2019-06-06 16:48:09,241: training iter 577, loss=0.06188949942588806 (9.821712s)
INFO:niftynet:2019-06-06 16:48:19,527: training iter 578, loss=0.061670612543821335 (10.285931s)
INFO:niftynet:2019-06-06 16:48:31,681: training iter 579, loss=0.06103674694895744 (12.152781s)
INFO:niftynet:2019-06-06 16:48:45,178: training iter 580, loss=0.06854436546564102 (13.497141s)
INFO:niftynet:2019-06-06 16:48:54,382: training iter 581, loss=0.06127522513270378 (9.159255s)
INFO:niftynet:2019-06-06 16:49:04,404: training iter 582, loss=0.059814076870679855 (10.021424s)
INFO:niftynet:2019-06-06 16:49:19,211: training iter 583, loss=0.06062578037381172 (14.807076s)
INFO:niftynet:2019-06-06 16:49:34,307: training iter 584, loss=0.06820110231637955 (15.095340s)
INFO:niftynet:2019-06-06 16:49:43,685: training iter 585, loss=0.06258992105722427 (9.377842s)
INFO:niftynet:2019-06-06 16:49:54,084: training iter 586, loss=0.06549123674631119 (10.398421s)
INFO:niftynet:2019-06-06 16:50:08,931: training iter 587, loss=0.0707806944847107 (14.846777s)
INFO:niftynet:2019-06-06 16:50:20,030: training iter 588, loss=0.05999673530459404 (11.098693s)
INFO:niftynet:2019-06-06 16:50:29,885: training iter 589, loss=0.06030310317873955 (9.853627s)
INFO:niftynet:2019-06-06 16:50:40,798: training iter 590, loss=0.05931004881858826 (10.911753s)
INFO:niftynet:2019-06-06 16:50:56,210: training iter 591, loss=0.07022431492805481 (15.403446s)
INFO:niftynet:2019-06-06 16:51:05,462: training iter 592, loss=0.05806833505630493 (9.251537s)
INFO:niftynet:2019-06-06 16:51:15,388: training iter 593, loss=0.06605121493339539 (9.926031s)
INFO:niftynet:2019-06-06 16:51:28,189: training iter 594, loss=0.06825730949640274 (12.800302s)
INFO:niftynet:2019-06-06 16:51:41,500: training iter 595, loss=0.062370914965867996 (13.296593s)
INFO:niftynet:2019-06-06 16:51:51,385: training iter 596, loss=0.06182115152478218 (9.885324s)
INFO:niftynet:2019-06-06 16:52:02,224: training iter 597, loss=0.059443484991788864 (10.838542s)
INFO:niftynet:2019-06-06 16:52:17,202: training iter 598, loss=0.06126205995678902 (14.977732s)
INFO:niftynet:2019-06-06 16:52:28,414: training iter 599, loss=0.05976923182606697 (11.211545s)
INFO:niftynet:2019-06-06 16:52:37,872: training iter 600, loss=0.06120423600077629 (9.457210s)
INFO:niftynet:2019-06-06 16:52:39,572: iter 600 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-06 16:52:50,695: training iter 601, loss=0.07092420011758804 (11.098590s)
INFO:niftynet:2019-06-06 16:53:02,220: training iter 602, loss=0.061288923025131226 (11.524517s)
INFO:niftynet:2019-06-06 16:53:12,226: training iter 603, loss=0.06431683897972107 (10.005541s)
INFO:niftynet:2019-06-06 16:53:27,219: training iter 604, loss=0.0657317265868187 (14.992608s)
INFO:niftynet:2019-06-06 16:53:42,075: training iter 605, loss=0.06141654774546623 (14.855565s)
INFO:niftynet:2019-06-06 16:53:53,714: training iter 606, loss=0.05830108001828194 (11.638921s)
INFO:niftynet:2019-06-06 16:54:03,149: training iter 607, loss=0.07575565576553345 (9.434104s)
INFO:niftynet:2019-06-06 16:54:13,970: training iter 608, loss=0.0761449858546257 (10.820347s)
INFO:niftynet:2019-06-06 16:54:29,567: training iter 609, loss=0.0585496723651886 (15.597134s)
INFO:niftynet:2019-06-06 16:54:38,543: training iter 610, loss=0.0665404424071312 (8.975259s)
INFO:niftynet:2019-06-06 16:54:48,885: training iter 611, loss=0.06433027237653732 (10.325666s)
INFO:niftynet:2019-06-06 16:55:03,051: training iter 612, loss=0.07463101297616959 (14.164799s)
INFO:niftynet:2019-06-06 16:55:17,193: training iter 613, loss=0.05746445059776306 (14.141928s)
