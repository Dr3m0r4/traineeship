INFO:niftynet:2019-06-17 10:09:09,853: set CUDA_VISIBLE_DEVICES to 0
INFO:niftynet:2019-06-17 10:09:09,853: starting segmentation application
INFO:niftynet:2019-06-17 10:09:09,853: `csv_file = ` not found, writing to "/home/julien/traineeship/mmiv/model/image.csv" instead.
INFO:niftynet:2019-06-17 10:09:09,853: [image] search file folders, writing csv file /home/julien/traineeship/mmiv/model/image.csv
INFO:niftynet:2019-06-17 10:09:09,894: `csv_file = ` not found, writing to "/home/julien/traineeship/mmiv/model/label.csv" instead.
INFO:niftynet:2019-06-17 10:09:09,894: [label] search file folders, writing csv file /home/julien/traineeship/mmiv/model/label.csv
INFO:niftynet:2019-06-17 10:09:09,940: 

Number of subjects 581, input section names: ['subject_id', 'image', 'label']
Dataset partitioning:
-- training 406 cases (69.88%),
-- validation 0 cases (0.00%),
-- inference 175 cases (30.12%).

INFO:niftynet:2019-06-17 10:09:12,258: Image reader: loading 406 subjects from sections ('image',) as input [image]
INFO:niftynet:2019-06-17 10:09:12,259: Image reader: loading 406 subjects from sections ('label',) as input [label]
INFO:niftynet:2019-06-17 10:09:12,261: Looking for the set of unique discrete labels from input label using 406 subjects
INFO:niftynet:2019-06-17 10:11:59,952: initialised uniform sampler {'image': (1, 144, 144, 144, 1, 1), 'image_location': (1, 7), 'label': (1, 144, 144, 144, 1, 1), 'label_location': (1, 7)} 
WARNING:niftynet:2019-06-17 10:11:59,956: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/engine/application_initializer.py:106: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.
Instructions for updating:
`normal` is a deprecated alias for `truncated_normal`
INFO:niftynet:2019-06-17 10:11:59,957: using DenseVNet
INFO:niftynet:2019-06-17 10:11:59,962: Initialising Dataset from 406 subjects...
WARNING:niftynet:2019-06-17 10:11:59,967: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/engine/image_window_dataset.py:300: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, use
    tf.py_function, which takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    
WARNING:niftynet:2019-06-17 10:12:00,154: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/grid_warper.py:291: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-17 10:12:01,244: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:niftynet:2019-06-17 10:12:01,478: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/activation.py:68: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:niftynet:2019-06-17 10:12:03,521: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/loss_segmentation.py:157: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-17 10:12:03,528: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/niftynet/layer/loss_segmentation.py:174: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:niftynet:2019-06-17 10:12:03,539: From /home/julien/.conda/envs/niftynet/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: calling sparse_reduce_sum (from tensorflow.python.ops.sparse_ops) with reduction_axes is deprecated and will be removed in a future version.
Instructions for updating:
reduction_axes is deprecated, use axis instead
INFO:niftynet:2019-06-17 10:12:15,023: Parameters from random initialisations ...
INFO:niftynet:2019-06-17 10:13:45,302: training iter 1, loss=0.7702064514160156 (90.277911s)
INFO:niftynet:2019-06-17 10:13:55,181: training iter 2, loss=0.8143153190612793 (9.879346s)
INFO:niftynet:2019-06-17 10:14:05,502: training iter 3, loss=0.7817090153694153 (10.320220s)
INFO:niftynet:2019-06-17 10:14:16,325: training iter 4, loss=0.8072037100791931 (10.822734s)
INFO:niftynet:2019-06-17 10:14:26,584: training iter 5, loss=0.7904176712036133 (10.258594s)
INFO:niftynet:2019-06-17 10:14:36,463: training iter 6, loss=0.802226722240448 (9.878459s)
INFO:niftynet:2019-06-17 10:14:47,472: training iter 7, loss=0.8077563643455505 (11.008132s)
INFO:niftynet:2019-06-17 10:14:58,161: training iter 8, loss=0.8134925961494446 (10.689354s)
INFO:niftynet:2019-06-17 10:15:08,362: training iter 9, loss=0.7944781184196472 (10.199962s)
INFO:niftynet:2019-06-17 10:15:37,623: training iter 10, loss=0.8029448390007019 (29.258485s)
INFO:niftynet:2019-06-17 10:15:47,581: training iter 11, loss=0.8163700699806213 (9.947194s)
INFO:niftynet:2019-06-17 10:15:57,977: training iter 12, loss=0.8090071678161621 (10.395589s)
INFO:niftynet:2019-06-17 10:16:08,845: training iter 13, loss=0.7960150837898254 (10.867816s)
INFO:niftynet:2019-06-17 10:16:19,335: training iter 14, loss=0.797616183757782 (10.488833s)
INFO:niftynet:2019-06-17 10:16:29,723: training iter 15, loss=0.8025233149528503 (10.388103s)
INFO:niftynet:2019-06-17 10:16:40,449: training iter 16, loss=0.8223244547843933 (10.725217s)
INFO:niftynet:2019-06-17 10:16:50,709: training iter 17, loss=0.8121165633201599 (10.259526s)
INFO:niftynet:2019-06-17 10:17:01,087: training iter 18, loss=0.7943918108940125 (10.369467s)
INFO:niftynet:2019-06-17 10:17:11,198: training iter 19, loss=0.8053216338157654 (10.110709s)
INFO:niftynet:2019-06-17 10:17:22,098: training iter 20, loss=0.7901787757873535 (10.899100s)
INFO:niftynet:2019-06-17 10:17:32,997: training iter 21, loss=0.800706684589386 (10.891851s)
INFO:niftynet:2019-06-17 10:17:42,892: training iter 22, loss=0.8071105480194092 (9.894231s)
INFO:niftynet:2019-06-17 10:17:52,999: training iter 23, loss=0.8020777702331543 (10.107157s)
INFO:niftynet:2019-06-17 10:18:03,538: training iter 24, loss=0.7882556915283203 (10.537802s)
INFO:niftynet:2019-06-17 10:18:17,494: iter 25 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:18:17,494: training iter 25, loss=0.7706689834594727 (10.330516s)
INFO:niftynet:2019-06-17 10:18:27,473: training iter 26, loss=0.8018345832824707 (9.978201s)
INFO:niftynet:2019-06-17 10:18:37,650: training iter 27, loss=0.8085202574729919 (10.177124s)
INFO:niftynet:2019-06-17 10:18:48,456: training iter 28, loss=0.7837967872619629 (10.804950s)
INFO:niftynet:2019-06-17 10:18:59,520: training iter 29, loss=0.80202716588974 (11.063484s)
INFO:niftynet:2019-06-17 10:19:09,485: training iter 30, loss=0.8059201240539551 (9.965552s)
INFO:niftynet:2019-06-17 10:19:20,069: training iter 31, loss=0.7913771271705627 (10.574781s)
INFO:niftynet:2019-06-17 10:19:30,599: training iter 32, loss=0.7806857228279114 (10.527436s)
INFO:niftynet:2019-06-17 10:19:41,058: training iter 33, loss=0.7873616218566895 (10.458446s)
INFO:niftynet:2019-06-17 10:19:51,356: training iter 34, loss=0.816861629486084 (10.297703s)
INFO:niftynet:2019-06-17 10:20:02,265: training iter 35, loss=0.795930802822113 (10.907792s)
INFO:niftynet:2019-06-17 10:20:12,394: training iter 36, loss=0.8074852824211121 (10.128793s)
INFO:niftynet:2019-06-17 10:20:22,170: training iter 37, loss=0.7972984910011292 (9.766413s)
INFO:niftynet:2019-06-17 10:20:32,911: training iter 38, loss=0.7823694348335266 (10.741180s)
INFO:niftynet:2019-06-17 10:20:43,278: training iter 39, loss=0.7948968410491943 (10.366127s)
INFO:niftynet:2019-06-17 10:20:53,323: training iter 40, loss=0.813607931137085 (10.044961s)
INFO:niftynet:2019-06-17 10:21:03,497: training iter 41, loss=0.7930262684822083 (10.166225s)
INFO:niftynet:2019-06-17 10:21:13,825: training iter 42, loss=0.811184823513031 (10.327158s)
INFO:niftynet:2019-06-17 10:21:24,108: training iter 43, loss=0.8204358220100403 (10.282765s)
INFO:niftynet:2019-06-17 10:21:34,123: training iter 44, loss=0.7961536049842834 (10.014720s)
INFO:niftynet:2019-06-17 10:21:44,740: training iter 45, loss=0.8224983215332031 (10.616890s)
INFO:niftynet:2019-06-17 10:21:55,614: training iter 46, loss=0.8090395927429199 (10.873333s)
INFO:niftynet:2019-06-17 10:22:05,884: training iter 47, loss=0.8047518134117126 (10.269993s)
INFO:niftynet:2019-06-17 10:22:15,876: training iter 48, loss=0.7972648739814758 (9.991114s)
INFO:niftynet:2019-06-17 10:22:26,447: training iter 49, loss=0.7959758639335632 (10.553586s)
INFO:niftynet:2019-06-17 10:22:39,156: iter 50 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:22:39,157: training iter 50, loss=0.799841582775116 (10.362182s)
INFO:niftynet:2019-06-17 10:22:49,110: training iter 51, loss=0.8158921599388123 (9.943934s)
INFO:niftynet:2019-06-17 10:22:58,955: training iter 52, loss=0.7999520301818848 (9.845005s)
INFO:niftynet:2019-06-17 10:23:09,397: training iter 53, loss=0.7855985164642334 (10.440548s)
INFO:niftynet:2019-06-17 10:23:20,624: training iter 54, loss=0.7961196303367615 (11.226947s)
INFO:niftynet:2019-06-17 10:23:30,949: training iter 55, loss=0.7847655415534973 (10.324272s)
INFO:niftynet:2019-06-17 10:23:41,681: training iter 56, loss=0.793814480304718 (10.732123s)
INFO:niftynet:2019-06-17 10:23:52,437: training iter 57, loss=0.8017072081565857 (10.727530s)
INFO:niftynet:2019-06-17 10:24:02,641: training iter 58, loss=0.7992152571678162 (10.203499s)
INFO:niftynet:2019-06-17 10:24:10,817: training iter 59, loss=0.7939372062683105 (8.175362s)
INFO:niftynet:2019-06-17 10:24:21,768: training iter 60, loss=0.8160794377326965 (10.950337s)
INFO:niftynet:2019-06-17 10:24:32,917: training iter 61, loss=0.7950811386108398 (11.141377s)
INFO:niftynet:2019-06-17 10:24:43,629: training iter 62, loss=0.7888930439949036 (10.711812s)
INFO:niftynet:2019-06-17 10:24:53,967: training iter 63, loss=0.7943966388702393 (10.337054s)
INFO:niftynet:2019-06-17 10:25:04,553: training iter 64, loss=0.818622887134552 (10.586514s)
INFO:niftynet:2019-06-17 10:25:15,045: training iter 65, loss=0.7921980023384094 (10.491657s)
INFO:niftynet:2019-06-17 10:25:25,683: training iter 66, loss=0.7928587794303894 (10.637524s)
INFO:niftynet:2019-06-17 10:25:36,277: training iter 67, loss=0.8004586696624756 (10.593305s)
INFO:niftynet:2019-06-17 10:25:46,937: training iter 68, loss=0.8014063835144043 (10.659534s)
INFO:niftynet:2019-06-17 10:25:57,680: training iter 69, loss=0.7998335957527161 (10.742628s)
INFO:niftynet:2019-06-17 10:26:08,112: training iter 70, loss=0.7901935577392578 (10.431737s)
INFO:niftynet:2019-06-17 10:26:18,393: training iter 71, loss=0.7826604247093201 (10.259327s)
INFO:niftynet:2019-06-17 10:26:28,989: training iter 72, loss=0.7858416438102722 (10.523196s)
INFO:niftynet:2019-06-17 10:26:39,147: training iter 73, loss=0.7965092658996582 (10.157698s)
INFO:niftynet:2019-06-17 10:26:49,632: training iter 74, loss=0.8029994368553162 (10.484411s)
INFO:niftynet:2019-06-17 10:27:02,176: iter 75 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:27:02,191: training iter 75, loss=0.7851459980010986 (10.485909s)
INFO:niftynet:2019-06-17 10:27:13,372: training iter 76, loss=0.8058196902275085 (11.174446s)
INFO:niftynet:2019-06-17 10:27:23,896: training iter 77, loss=0.7891995906829834 (10.523945s)
INFO:niftynet:2019-06-17 10:27:34,320: training iter 78, loss=0.7922433018684387 (10.422832s)
INFO:niftynet:2019-06-17 10:27:45,146: training iter 79, loss=0.802836000919342 (10.825590s)
INFO:niftynet:2019-06-17 10:27:55,725: training iter 80, loss=0.8090419769287109 (10.579339s)
INFO:niftynet:2019-06-17 10:28:05,930: training iter 81, loss=0.7942361235618591 (10.196550s)
INFO:niftynet:2019-06-17 10:28:16,454: training iter 82, loss=0.8086053729057312 (10.524013s)
INFO:niftynet:2019-06-17 10:28:26,718: training iter 83, loss=0.8071122169494629 (10.263318s)
INFO:niftynet:2019-06-17 10:28:37,499: training iter 84, loss=0.7870902419090271 (10.781295s)
INFO:niftynet:2019-06-17 10:28:47,316: training iter 85, loss=0.8014702200889587 (9.816483s)
INFO:niftynet:2019-06-17 10:28:57,877: training iter 86, loss=0.8032400012016296 (10.560717s)
INFO:niftynet:2019-06-17 10:29:08,238: training iter 87, loss=0.8058893084526062 (10.360005s)
INFO:niftynet:2019-06-17 10:29:18,504: training iter 88, loss=0.7911363244056702 (10.265459s)
INFO:niftynet:2019-06-17 10:29:29,074: training iter 89, loss=0.7840926051139832 (10.569885s)
INFO:niftynet:2019-06-17 10:29:39,890: training iter 90, loss=0.7918218970298767 (10.815112s)
INFO:niftynet:2019-06-17 10:29:50,683: training iter 91, loss=0.7986640334129333 (10.784793s)
INFO:niftynet:2019-06-17 10:30:00,952: training iter 92, loss=0.8169068694114685 (10.266574s)
INFO:niftynet:2019-06-17 10:30:11,855: training iter 93, loss=0.7883636951446533 (10.902781s)
INFO:niftynet:2019-06-17 10:30:22,298: training iter 94, loss=0.792640209197998 (10.442052s)
INFO:niftynet:2019-06-17 10:30:32,146: training iter 95, loss=0.8186368942260742 (9.848105s)
INFO:niftynet:2019-06-17 10:30:42,643: training iter 96, loss=0.8147684931755066 (10.496349s)
INFO:niftynet:2019-06-17 10:30:53,726: training iter 97, loss=0.8115327954292297 (11.082119s)
INFO:niftynet:2019-06-17 10:31:03,987: training iter 98, loss=0.8187589645385742 (10.261265s)
INFO:niftynet:2019-06-17 10:31:14,295: training iter 99, loss=0.8031023144721985 (10.305754s)
INFO:niftynet:2019-06-17 10:31:27,276: iter 100 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:31:27,317: training iter 100, loss=0.7979596257209778 (10.590933s)
INFO:niftynet:2019-06-17 10:31:38,220: training iter 101, loss=0.7986372113227844 (10.892929s)
INFO:niftynet:2019-06-17 10:31:48,482: training iter 102, loss=0.7964522242546082 (10.260959s)
INFO:niftynet:2019-06-17 10:31:58,735: training iter 103, loss=0.8022629618644714 (10.252795s)
INFO:niftynet:2019-06-17 10:32:09,247: training iter 104, loss=0.8007128834724426 (10.498951s)
INFO:niftynet:2019-06-17 10:32:19,862: training iter 105, loss=0.8154487013816833 (10.614793s)
INFO:niftynet:2019-06-17 10:32:30,007: training iter 106, loss=0.7801907658576965 (10.143921s)
INFO:niftynet:2019-06-17 10:32:40,513: training iter 107, loss=0.7941840291023254 (10.505482s)
INFO:niftynet:2019-06-17 10:32:51,781: training iter 108, loss=0.7949258685112 (11.268219s)
INFO:niftynet:2019-06-17 10:33:02,813: training iter 109, loss=0.8044314980506897 (11.031630s)
INFO:niftynet:2019-06-17 10:33:13,167: training iter 110, loss=0.798274576663971 (10.352943s)
INFO:niftynet:2019-06-17 10:33:23,560: training iter 111, loss=0.7967172265052795 (10.384109s)
INFO:niftynet:2019-06-17 10:33:34,386: training iter 112, loss=0.8028469085693359 (10.825914s)
INFO:niftynet:2019-06-17 10:33:45,038: training iter 113, loss=0.7925544381141663 (10.651317s)
INFO:niftynet:2019-06-17 10:33:55,790: training iter 114, loss=0.7732517123222351 (10.751629s)
INFO:niftynet:2019-06-17 10:34:06,929: training iter 115, loss=0.7986040711402893 (11.139428s)
INFO:niftynet:2019-06-17 10:34:17,972: training iter 116, loss=0.7948915362358093 (11.041698s)
INFO:niftynet:2019-06-17 10:34:28,753: training iter 117, loss=0.8048639297485352 (10.781410s)
INFO:niftynet:2019-06-17 10:34:39,463: training iter 118, loss=0.8021612167358398 (10.709509s)
INFO:niftynet:2019-06-17 10:34:50,427: training iter 119, loss=0.8017373085021973 (10.962940s)
INFO:niftynet:2019-06-17 10:35:00,977: training iter 120, loss=0.8038701415061951 (10.550035s)
INFO:niftynet:2019-06-17 10:35:11,223: training iter 121, loss=0.8174233436584473 (10.237273s)
INFO:niftynet:2019-06-17 10:35:21,483: training iter 122, loss=0.8116598129272461 (10.259621s)
INFO:niftynet:2019-06-17 10:35:31,963: training iter 123, loss=0.8122349381446838 (10.480102s)
INFO:niftynet:2019-06-17 10:35:42,508: training iter 124, loss=0.8098034262657166 (10.544177s)
INFO:niftynet:2019-06-17 10:35:55,512: iter 125 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:35:55,513: training iter 125, loss=0.7868135571479797 (9.977114s)
INFO:niftynet:2019-06-17 10:36:04,822: training iter 126, loss=0.8127827644348145 (9.309310s)
INFO:niftynet:2019-06-17 10:36:15,019: training iter 127, loss=0.8081717491149902 (10.196508s)
INFO:niftynet:2019-06-17 10:36:24,437: training iter 128, loss=0.8042486310005188 (9.417598s)
INFO:niftynet:2019-06-17 10:36:35,579: training iter 129, loss=0.8007621765136719 (11.141524s)
INFO:niftynet:2019-06-17 10:36:46,256: training iter 130, loss=0.804319441318512 (10.676723s)
INFO:niftynet:2019-06-17 10:36:57,080: training iter 131, loss=0.7882176041603088 (10.803733s)
INFO:niftynet:2019-06-17 10:37:07,178: training iter 132, loss=0.8054823875427246 (10.097433s)
INFO:niftynet:2019-06-17 10:37:17,728: training iter 133, loss=0.7890061736106873 (10.549464s)
INFO:niftynet:2019-06-17 10:37:28,579: training iter 134, loss=0.8102626800537109 (10.851175s)
INFO:niftynet:2019-06-17 10:37:38,831: training iter 135, loss=0.7839600443840027 (10.251508s)
INFO:niftynet:2019-06-17 10:37:49,121: training iter 136, loss=0.7956464886665344 (10.289097s)
INFO:niftynet:2019-06-17 10:37:59,635: training iter 137, loss=0.8252654671669006 (10.514203s)
INFO:niftynet:2019-06-17 10:38:10,585: training iter 138, loss=0.789838969707489 (10.949508s)
INFO:niftynet:2019-06-17 10:38:21,112: training iter 139, loss=0.7965688705444336 (10.526784s)
INFO:niftynet:2019-06-17 10:38:30,945: training iter 140, loss=0.7980807423591614 (9.832663s)
INFO:niftynet:2019-06-17 10:38:41,678: training iter 141, loss=0.7962924838066101 (10.720408s)
INFO:niftynet:2019-06-17 10:38:52,272: training iter 142, loss=0.7977101802825928 (10.593445s)
INFO:niftynet:2019-06-17 10:39:02,966: training iter 143, loss=0.788404643535614 (10.693590s)
INFO:niftynet:2019-06-17 10:39:12,875: training iter 144, loss=0.8066012263298035 (9.908720s)
INFO:niftynet:2019-06-17 10:39:23,303: training iter 145, loss=0.8084173798561096 (10.427650s)
INFO:niftynet:2019-06-17 10:39:33,838: training iter 146, loss=0.8037697672843933 (10.534867s)
INFO:niftynet:2019-06-17 10:39:43,456: training iter 147, loss=0.8046805262565613 (9.617401s)
INFO:niftynet:2019-06-17 10:39:54,359: training iter 148, loss=0.8012199401855469 (10.902632s)
INFO:niftynet:2019-06-17 10:40:04,844: training iter 149, loss=0.7886742949485779 (10.485019s)
INFO:niftynet:2019-06-17 10:40:17,947: iter 150 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:40:17,947: training iter 150, loss=0.7839693427085876 (10.278353s)
INFO:niftynet:2019-06-17 10:40:28,065: training iter 151, loss=0.7851994633674622 (10.099423s)
INFO:niftynet:2019-06-17 10:40:38,124: training iter 152, loss=0.8095988631248474 (10.058052s)
INFO:niftynet:2019-06-17 10:40:48,922: training iter 153, loss=0.7919015288352966 (10.797593s)
INFO:niftynet:2019-06-17 10:40:59,407: training iter 154, loss=0.8041380047798157 (10.484913s)
INFO:niftynet:2019-06-17 10:41:09,808: training iter 155, loss=0.77158123254776 (10.400633s)
INFO:niftynet:2019-06-17 10:41:20,493: training iter 156, loss=0.7977561354637146 (10.684863s)
INFO:niftynet:2019-06-17 10:41:31,229: training iter 157, loss=0.7842079997062683 (10.735733s)
INFO:niftynet:2019-06-17 10:41:41,865: training iter 158, loss=0.7987663149833679 (10.634899s)
INFO:niftynet:2019-06-17 10:41:52,113: training iter 159, loss=0.8047676682472229 (10.247511s)
INFO:niftynet:2019-06-17 10:42:02,179: training iter 160, loss=0.7804470062255859 (10.065805s)
INFO:niftynet:2019-06-17 10:42:13,070: training iter 161, loss=0.796675443649292 (10.882411s)
INFO:niftynet:2019-06-17 10:42:23,539: training iter 162, loss=0.8159146308898926 (10.468973s)
INFO:niftynet:2019-06-17 10:42:33,930: training iter 163, loss=0.807058572769165 (10.391071s)
INFO:niftynet:2019-06-17 10:42:43,995: training iter 164, loss=0.7963352799415588 (10.064175s)
INFO:niftynet:2019-06-17 10:42:53,968: training iter 165, loss=0.7991692423820496 (9.972971s)
INFO:niftynet:2019-06-17 10:43:04,817: training iter 166, loss=0.8079359531402588 (10.848675s)
INFO:niftynet:2019-06-17 10:43:15,260: training iter 167, loss=0.7902379631996155 (10.441172s)
INFO:niftynet:2019-06-17 10:43:25,251: training iter 168, loss=0.8024763464927673 (9.990536s)
INFO:niftynet:2019-06-17 10:43:35,995: training iter 169, loss=0.8029613494873047 (10.743739s)
INFO:niftynet:2019-06-17 10:43:46,358: training iter 170, loss=0.8132858276367188 (10.363019s)
INFO:niftynet:2019-06-17 10:43:56,717: training iter 171, loss=0.8172252774238586 (10.350032s)
INFO:niftynet:2019-06-17 10:44:07,487: training iter 172, loss=0.7782934308052063 (10.769728s)
INFO:niftynet:2019-06-17 10:44:17,801: training iter 173, loss=0.8009814620018005 (10.313685s)
INFO:niftynet:2019-06-17 10:44:28,756: training iter 174, loss=0.7921368479728699 (10.955021s)
INFO:niftynet:2019-06-17 10:44:41,571: iter 175 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:44:41,572: training iter 175, loss=0.8024802803993225 (10.182906s)
INFO:niftynet:2019-06-17 10:44:51,855: training iter 176, loss=0.791869580745697 (10.282861s)
INFO:niftynet:2019-06-17 10:45:02,540: training iter 177, loss=0.8089547753334045 (10.684751s)
INFO:niftynet:2019-06-17 10:45:12,252: training iter 178, loss=0.7947864532470703 (9.711852s)
INFO:niftynet:2019-06-17 10:45:22,123: training iter 179, loss=0.7936022281646729 (9.870269s)
INFO:niftynet:2019-06-17 10:45:32,318: training iter 180, loss=0.8001136183738708 (10.194843s)
INFO:niftynet:2019-06-17 10:45:43,070: training iter 181, loss=0.8109319806098938 (10.743442s)
INFO:niftynet:2019-06-17 10:45:53,466: training iter 182, loss=0.7998887896537781 (10.394969s)
INFO:niftynet:2019-06-17 10:46:03,616: training iter 183, loss=0.8079562187194824 (10.149750s)
INFO:niftynet:2019-06-17 10:46:14,219: training iter 184, loss=0.7836980819702148 (10.602317s)
INFO:niftynet:2019-06-17 10:46:24,691: training iter 185, loss=0.7970561385154724 (10.463474s)
INFO:niftynet:2019-06-17 10:46:34,706: training iter 186, loss=0.7827513813972473 (10.013788s)
INFO:niftynet:2019-06-17 10:46:45,138: training iter 187, loss=0.7948999404907227 (10.431741s)
INFO:niftynet:2019-06-17 10:46:55,615: training iter 188, loss=0.8062741756439209 (10.476565s)
INFO:niftynet:2019-06-17 10:47:06,006: training iter 189, loss=0.7920824885368347 (10.390732s)
INFO:niftynet:2019-06-17 10:47:15,655: training iter 190, loss=0.8053342700004578 (9.648343s)
INFO:niftynet:2019-06-17 10:47:25,993: training iter 191, loss=0.800717830657959 (10.316098s)
INFO:niftynet:2019-06-17 10:47:36,200: training iter 192, loss=0.7948629856109619 (10.205894s)
INFO:niftynet:2019-06-17 10:47:46,367: training iter 193, loss=0.8107934594154358 (10.166787s)
INFO:niftynet:2019-06-17 10:47:56,693: training iter 194, loss=0.797503650188446 (10.313677s)
INFO:niftynet:2019-06-17 10:48:04,186: training iter 195, loss=0.7930970788002014 (7.493008s)
INFO:niftynet:2019-06-17 10:48:14,911: training iter 196, loss=0.787355899810791 (10.724358s)
INFO:niftynet:2019-06-17 10:48:25,725: training iter 197, loss=0.8028025031089783 (10.814138s)
INFO:niftynet:2019-06-17 10:48:36,418: training iter 198, loss=0.8005589842796326 (10.692022s)
INFO:niftynet:2019-06-17 10:48:46,181: training iter 199, loss=0.8131323456764221 (9.763404s)
INFO:niftynet:2019-06-17 10:48:58,923: iter 200 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:48:58,924: training iter 200, loss=0.7859073281288147 (10.347351s)
INFO:niftynet:2019-06-17 10:49:09,262: training iter 201, loss=0.8061957359313965 (10.328442s)
INFO:niftynet:2019-06-17 10:49:20,096: training iter 202, loss=0.8092775344848633 (10.833127s)
INFO:niftynet:2019-06-17 10:49:29,877: training iter 203, loss=0.8093567490577698 (9.780466s)
INFO:niftynet:2019-06-17 10:49:40,772: training iter 204, loss=0.8152728080749512 (10.895329s)
INFO:niftynet:2019-06-17 10:49:51,494: training iter 205, loss=0.7980166077613831 (10.721282s)
INFO:niftynet:2019-06-17 10:50:02,076: training iter 206, loss=0.8167644143104553 (10.581625s)
INFO:niftynet:2019-06-17 10:50:12,406: training iter 207, loss=0.8081458210945129 (10.329365s)
INFO:niftynet:2019-06-17 10:50:23,774: training iter 208, loss=0.8025214076042175 (11.367459s)
INFO:niftynet:2019-06-17 10:50:34,182: training iter 209, loss=0.8024999499320984 (10.407273s)
INFO:niftynet:2019-06-17 10:50:44,626: training iter 210, loss=0.8053558468818665 (10.443769s)
INFO:niftynet:2019-06-17 10:50:55,329: training iter 211, loss=0.8048000335693359 (10.695510s)
INFO:niftynet:2019-06-17 10:51:05,430: training iter 212, loss=0.7888687252998352 (10.100875s)
INFO:niftynet:2019-06-17 10:51:15,991: training iter 213, loss=0.807190477848053 (10.560492s)
INFO:niftynet:2019-06-17 10:51:26,333: training iter 214, loss=0.7848729491233826 (10.342105s)
INFO:niftynet:2019-06-17 10:51:36,643: training iter 215, loss=0.784984290599823 (10.309079s)
INFO:niftynet:2019-06-17 10:51:47,569: training iter 216, loss=0.7980673313140869 (10.864466s)
INFO:niftynet:2019-06-17 10:51:58,108: training iter 217, loss=0.8001787066459656 (10.537719s)
INFO:niftynet:2019-06-17 10:52:08,774: training iter 218, loss=0.7856152653694153 (10.666392s)
INFO:niftynet:2019-06-17 10:52:19,488: training iter 219, loss=0.8044363856315613 (10.713029s)
INFO:niftynet:2019-06-17 10:52:30,006: training iter 220, loss=0.787045955657959 (10.495654s)
INFO:niftynet:2019-06-17 10:52:40,364: training iter 221, loss=0.8064705729484558 (10.347082s)
INFO:niftynet:2019-06-17 10:52:50,877: training iter 222, loss=0.806784451007843 (10.511397s)
INFO:niftynet:2019-06-17 10:53:01,201: training iter 223, loss=0.8156984448432922 (10.322856s)
INFO:niftynet:2019-06-17 10:53:11,743: training iter 224, loss=0.7893238663673401 (10.541907s)
INFO:niftynet:2019-06-17 10:53:23,926: iter 225 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:53:23,926: training iter 225, loss=0.8019372820854187 (10.151697s)
INFO:niftynet:2019-06-17 10:53:35,118: training iter 226, loss=0.7904732823371887 (11.191891s)
INFO:niftynet:2019-06-17 10:53:45,981: training iter 227, loss=0.7949816584587097 (10.862272s)
INFO:niftynet:2019-06-17 10:53:56,644: training iter 228, loss=0.7984560132026672 (10.662689s)
INFO:niftynet:2019-06-17 10:54:07,270: training iter 229, loss=0.817418098449707 (10.625689s)
INFO:niftynet:2019-06-17 10:54:18,003: training iter 230, loss=0.7997598648071289 (10.732191s)
INFO:niftynet:2019-06-17 10:54:28,277: training iter 231, loss=0.7766271233558655 (10.256198s)
INFO:niftynet:2019-06-17 10:54:38,709: training iter 232, loss=0.7878955006599426 (10.431654s)
INFO:niftynet:2019-06-17 10:54:49,693: training iter 233, loss=0.7767994403839111 (10.925096s)
INFO:niftynet:2019-06-17 10:55:00,485: training iter 234, loss=0.8051669597625732 (10.790990s)
INFO:niftynet:2019-06-17 10:55:11,062: training iter 235, loss=0.7892029881477356 (10.576470s)
INFO:niftynet:2019-06-17 10:55:22,377: training iter 236, loss=0.8137099146842957 (11.315262s)
INFO:niftynet:2019-06-17 10:55:33,438: training iter 237, loss=0.7941340804100037 (11.044671s)
INFO:niftynet:2019-06-17 10:55:43,637: training iter 238, loss=0.7828803062438965 (10.199185s)
INFO:niftynet:2019-06-17 10:55:54,734: training iter 239, loss=0.8008863925933838 (11.096486s)
INFO:niftynet:2019-06-17 10:56:05,853: training iter 240, loss=0.7980983853340149 (11.118210s)
INFO:niftynet:2019-06-17 10:56:16,479: training iter 241, loss=0.7928637862205505 (10.616845s)
INFO:niftynet:2019-06-17 10:56:27,584: training iter 242, loss=0.7822890877723694 (11.104206s)
INFO:niftynet:2019-06-17 10:56:38,463: training iter 243, loss=0.7959626317024231 (10.878839s)
INFO:niftynet:2019-06-17 10:56:49,265: training iter 244, loss=0.7837875485420227 (10.801588s)
INFO:niftynet:2019-06-17 10:57:00,071: training iter 245, loss=0.8190900683403015 (10.787982s)
INFO:niftynet:2019-06-17 10:57:10,515: training iter 246, loss=0.7953370213508606 (10.443382s)
INFO:niftynet:2019-06-17 10:57:21,443: training iter 247, loss=0.8090505599975586 (10.927610s)
INFO:niftynet:2019-06-17 10:57:31,558: training iter 248, loss=0.7867209911346436 (10.114820s)
INFO:niftynet:2019-06-17 10:57:42,230: training iter 249, loss=0.7808756828308105 (10.645054s)
INFO:niftynet:2019-06-17 10:57:54,659: iter 250 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 10:57:54,660: training iter 250, loss=0.7917494773864746 (10.423426s)
INFO:niftynet:2019-06-17 10:58:05,662: training iter 251, loss=0.7996676564216614 (10.994834s)
INFO:niftynet:2019-06-17 10:58:16,185: training iter 252, loss=0.7916529178619385 (10.522694s)
INFO:niftynet:2019-06-17 10:58:27,066: training iter 253, loss=0.8072978854179382 (10.879925s)
INFO:niftynet:2019-06-17 10:58:37,609: training iter 254, loss=0.8154551386833191 (10.543378s)
INFO:niftynet:2019-06-17 10:58:48,592: training iter 255, loss=0.7971029281616211 (10.981385s)
INFO:niftynet:2019-06-17 10:58:59,518: training iter 256, loss=0.8002966046333313 (10.926008s)
INFO:niftynet:2019-06-17 10:59:10,205: training iter 257, loss=0.7885361313819885 (10.686361s)
INFO:niftynet:2019-06-17 10:59:21,072: training iter 258, loss=0.788865864276886 (10.867273s)
INFO:niftynet:2019-06-17 10:59:31,730: training iter 259, loss=0.7919256091117859 (10.657142s)
INFO:niftynet:2019-06-17 10:59:42,714: training iter 260, loss=0.7982783317565918 (10.932792s)
INFO:niftynet:2019-06-17 10:59:53,203: training iter 261, loss=0.812890350818634 (10.480421s)
INFO:niftynet:2019-06-17 11:00:03,920: training iter 262, loss=0.8198332786560059 (10.717092s)
INFO:niftynet:2019-06-17 11:00:12,520: training iter 263, loss=0.7981092929840088 (8.599060s)
INFO:niftynet:2019-06-17 11:00:23,545: training iter 264, loss=0.8049644827842712 (11.017092s)
INFO:niftynet:2019-06-17 11:00:35,846: training iter 265, loss=0.8022791743278503 (12.300693s)
INFO:niftynet:2019-06-17 11:00:45,696: training iter 266, loss=0.7981989979743958 (9.849288s)
INFO:niftynet:2019-06-17 11:00:56,606: training iter 267, loss=0.784884512424469 (10.907597s)
INFO:niftynet:2019-06-17 11:01:07,119: training iter 268, loss=0.8145096898078918 (10.500566s)
INFO:niftynet:2019-06-17 11:01:17,430: training iter 269, loss=0.7949368357658386 (10.310912s)
INFO:niftynet:2019-06-17 11:01:28,444: training iter 270, loss=0.7909591794013977 (11.013635s)
INFO:niftynet:2019-06-17 11:01:39,095: training iter 271, loss=0.8032390475273132 (10.637996s)
INFO:niftynet:2019-06-17 11:01:50,225: training iter 272, loss=0.8039540648460388 (11.129471s)
INFO:niftynet:2019-06-17 11:02:00,684: training iter 273, loss=0.8103022575378418 (10.458885s)
INFO:niftynet:2019-06-17 11:02:11,574: training iter 274, loss=0.799954354763031 (10.889876s)
INFO:niftynet:2019-06-17 11:02:24,139: iter 275 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 11:02:24,140: training iter 275, loss=0.8132388591766357 (10.305682s)
INFO:niftynet:2019-06-17 11:02:34,313: training iter 276, loss=0.7971331477165222 (10.173133s)
INFO:niftynet:2019-06-17 11:02:44,892: training iter 277, loss=0.8081867694854736 (10.577446s)
INFO:niftynet:2019-06-17 11:02:55,240: training iter 278, loss=0.8005192279815674 (10.347699s)
INFO:niftynet:2019-06-17 11:03:05,581: training iter 279, loss=0.801408052444458 (10.340732s)
INFO:niftynet:2019-06-17 11:03:16,057: training iter 280, loss=0.8055415749549866 (10.475424s)
INFO:niftynet:2019-06-17 11:03:26,701: training iter 281, loss=0.7929933071136475 (10.603794s)
INFO:niftynet:2019-06-17 11:03:37,429: training iter 282, loss=0.810528576374054 (10.727480s)
INFO:niftynet:2019-06-17 11:03:48,072: training iter 283, loss=0.7992604374885559 (10.642054s)
INFO:niftynet:2019-06-17 11:03:58,502: training iter 284, loss=0.7978522777557373 (10.430464s)
INFO:niftynet:2019-06-17 11:04:09,292: training iter 285, loss=0.7991054058074951 (10.789551s)
INFO:niftynet:2019-06-17 11:04:19,933: training iter 286, loss=0.7944755554199219 (10.640166s)
INFO:niftynet:2019-06-17 11:04:30,355: training iter 287, loss=0.8062170147895813 (10.419034s)
INFO:niftynet:2019-06-17 11:04:40,513: training iter 288, loss=0.8022589683532715 (10.157575s)
INFO:niftynet:2019-06-17 11:04:51,266: training iter 289, loss=0.7921385765075684 (10.752624s)
INFO:niftynet:2019-06-17 11:05:01,472: training iter 290, loss=0.8088557124137878 (10.205309s)
INFO:niftynet:2019-06-17 11:05:11,465: training iter 291, loss=0.8076615333557129 (9.984149s)
INFO:niftynet:2019-06-17 11:05:22,588: training iter 292, loss=0.7823242545127869 (11.117502s)
INFO:niftynet:2019-06-17 11:05:33,405: training iter 293, loss=0.7918874621391296 (10.816307s)
INFO:niftynet:2019-06-17 11:05:43,497: training iter 294, loss=0.7979611754417419 (10.091631s)
INFO:niftynet:2019-06-17 11:05:53,585: training iter 295, loss=0.8280341029167175 (10.087704s)
INFO:niftynet:2019-06-17 11:06:04,718: training iter 296, loss=0.8022487759590149 (11.132571s)
INFO:niftynet:2019-06-17 11:06:14,837: training iter 297, loss=0.8025783896446228 (10.118744s)
INFO:niftynet:2019-06-17 11:06:25,873: training iter 298, loss=0.8024893403053284 (11.035129s)
INFO:niftynet:2019-06-17 11:06:36,492: training iter 299, loss=0.7858940958976746 (10.618817s)
INFO:niftynet:2019-06-17 11:06:49,482: iter 300 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 11:06:49,482: training iter 300, loss=0.8244624733924866 (10.425204s)
INFO:niftynet:2019-06-17 11:07:00,316: training iter 301, loss=0.8095092177391052 (10.826122s)
INFO:niftynet:2019-06-17 11:07:10,630: training iter 302, loss=0.7955694794654846 (10.313312s)
INFO:niftynet:2019-06-17 11:07:21,829: training iter 303, loss=0.8142617344856262 (11.199018s)
INFO:niftynet:2019-06-17 11:07:32,467: training iter 304, loss=0.8234691619873047 (10.637380s)
INFO:niftynet:2019-06-17 11:07:42,778: training iter 305, loss=0.7960308194160461 (10.311333s)
INFO:niftynet:2019-06-17 11:07:53,332: training iter 306, loss=0.7904456257820129 (10.550362s)
INFO:niftynet:2019-06-17 11:08:04,026: training iter 307, loss=0.7804571986198425 (10.693789s)
INFO:niftynet:2019-06-17 11:08:14,860: training iter 308, loss=0.8131446242332458 (10.833274s)
INFO:niftynet:2019-06-17 11:08:25,277: training iter 309, loss=0.7980661392211914 (10.416895s)
INFO:niftynet:2019-06-17 11:08:36,245: training iter 310, loss=0.8073918223381042 (10.968035s)
INFO:niftynet:2019-06-17 11:08:47,334: training iter 311, loss=0.7844040989875793 (11.036569s)
INFO:niftynet:2019-06-17 11:08:57,425: training iter 312, loss=0.8034217953681946 (10.079668s)
INFO:niftynet:2019-06-17 11:09:07,851: training iter 313, loss=0.8018510937690735 (10.425712s)
INFO:niftynet:2019-06-17 11:09:18,364: training iter 314, loss=0.7879297733306885 (10.512720s)
INFO:niftynet:2019-06-17 11:09:28,870: training iter 315, loss=0.7952353358268738 (10.504745s)
INFO:niftynet:2019-06-17 11:09:39,648: training iter 316, loss=0.7978663444519043 (10.778119s)
INFO:niftynet:2019-06-17 11:09:49,815: training iter 317, loss=0.8017860054969788 (10.166479s)
INFO:niftynet:2019-06-17 11:10:00,039: training iter 318, loss=0.7865471839904785 (10.223434s)
INFO:niftynet:2019-06-17 11:10:10,913: training iter 319, loss=0.7959633469581604 (10.872576s)
INFO:niftynet:2019-06-17 11:10:22,431: training iter 320, loss=0.7955746650695801 (11.518200s)
INFO:niftynet:2019-06-17 11:10:32,089: training iter 321, loss=0.787991464138031 (9.639047s)
INFO:niftynet:2019-06-17 11:10:42,657: training iter 322, loss=0.7957083582878113 (10.566921s)
INFO:niftynet:2019-06-17 11:10:53,753: training iter 323, loss=0.8166809678077698 (11.089477s)
INFO:niftynet:2019-06-17 11:11:06,395: training iter 324, loss=0.8081087470054626 (12.642119s)
INFO:niftynet:2019-06-17 11:11:19,345: iter 325 saved: /home/julien/traineeship/mmiv/model/models/model.ckpt
INFO:niftynet:2019-06-17 11:11:19,345: training iter 325, loss=0.7959243655204773 (10.278878s)
INFO:niftynet:2019-06-17 11:11:29,187: training iter 326, loss=0.8046905398368835 (9.841273s)
INFO:niftynet:2019-06-17 11:11:39,411: training iter 327, loss=0.8039663434028625 (10.223502s)
INFO:niftynet:2019-06-17 11:11:50,293: training iter 328, loss=0.7766716480255127 (10.882275s)
INFO:niftynet:2019-06-17 11:12:01,029: training iter 329, loss=0.7899441719055176 (10.735211s)
INFO:niftynet:2019-06-17 11:12:11,387: training iter 330, loss=0.7904636263847351 (10.357421s)
INFO:niftynet:2019-06-17 11:12:19,373: training iter 331, loss=0.8008663058280945 (7.978645s)
INFO:niftynet:2019-06-17 11:12:30,065: training iter 332, loss=0.7966340184211731 (10.691242s)
INFO:niftynet:2019-06-17 11:12:43,514: training iter 333, loss=0.7995011806488037 (13.449303s)
INFO:niftynet:2019-06-17 11:12:53,785: training iter 334, loss=0.8111923336982727 (10.269874s)
INFO:niftynet:2019-06-17 11:13:03,902: training iter 335, loss=0.7987346053123474 (10.115183s)
INFO:niftynet:2019-06-17 11:13:14,886: training iter 336, loss=0.7946076393127441 (10.983425s)
INFO:niftynet:2019-06-17 11:13:25,813: training iter 337, loss=0.7899757027626038 (10.926092s)
INFO:niftynet:2019-06-17 11:13:36,439: training iter 338, loss=0.7963210940361023 (10.626205s)
